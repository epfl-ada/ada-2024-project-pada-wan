{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to launch a succesfull beer ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <b>Group</b> : pada-wan "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First exploration of the dataset\n",
    "\n",
    "This notebook serves as a first exploration of the dataset. We analyzed ratings, review characteristics, user bases and evolution of ratings over time. \n",
    "This helps us understand the beer market and the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of content\n",
    "- [How to launch a successful beer?](#how-to-launch-a-succesfull-beer-)\n",
    "    - [First exploration of the dataset](#first-exploration-of-the-dataset-)\n",
    "    - [Info about Datasets](#info-about-datasets)\n",
    "        - [beers.csv](#beerscsv)\n",
    "        - [breweries.csv](#breweriescsv)\n",
    "        - [reviews.csv](#reviewscsv)\n",
    "        - [ratings.csv](#ratingscsv)\n",
    "        - [users.csv](#userscsv)\n",
    "    - [Summary of Ratings](#summary-of-ratings)\n",
    "        - [Dataset: BeerAdvocate](#dataset-beeradvocate)\n",
    "        - [Dataset: RateBeer](#dataset-ratebeer)\n",
    "        - [Dataset: Matched Beer Data](#dataset-matched-beer-data)\n",
    "    - [Part I: Dataset initialization and loading into a pandas DataFrame](#part-i--dataset-initialization-and-loading-into-a-pandas-dataframe-)\n",
    "    - [Part 2: Inspection of the data](#part-2--inspection-of-the-data-)\n",
    "        - [Most reviewed beer](#most-reviewed-beer)\n",
    "        - [Most reviewed brewery](#most-reviewed-brewery)\n",
    "    - [Part 3: Analysis of Customer Identity and origin](#part-3--analysis-of-customer-identity-and-origin)\n",
    "        - [Number of reviewers per country](#number-of-reviewers-per-country)\n",
    "        - [Average grade per country](#average-grade-per-country)\n",
    "        - [Number of breweries per country](#number-of-breweries-per-country)\n",
    "        - [Plots](#plots)\n",
    "    - [Part 4: Time analysis](#part-4--time-analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Info about Datasets\n",
    "\n",
    "### 0.1. beers.csv\n",
    "Contains information about the beers, such as the name, style, and brewery.\n",
    "### 0.2. breweries.csv\n",
    "Contains information about the breweries, such as the name and location.\n",
    "### 0.3. reviews.csv\n",
    "Contains information about the reviews, such as the beer ID, user ID, and rating.\n",
    "### 0.4. ratings.csv\n",
    "Contains information about the ratings, such as the beer ID, user ID, and rating.\n",
    "### 0.5. users.csv\n",
    "Contains information about the users, such as the username and age.\n",
    "---\n",
    "# Summary of Ratings\n",
    "\n",
    "## Dataset: BeerAdvocate\n",
    "\n",
    "- **ba_abv**: 4.8 - Percentage alcohol\n",
    "- **ba_avg**: 3.45 - Average rating (out of 5) of the beer\n",
    "- **ba_avg_computed**: 3.439867 - Computed average rating (out of 5) of the beer\n",
    "- **ba_avg_matched_valid_ratings**: 3.504068\n",
    "- **ba_ba_score**: 80.0 - BA Score is the beer's overall score (out of 100) based on its ranking within its style category, based on a custom Bayesian algorithm\n",
    "- **ba_beer_id**: 19827 - Unique ID for the beer\n",
    "- **ba_beer_name**: Legbiter - Name of the beer\n",
    "- **ba_beer_wout_brewery_name**: Legbiter - Name of the beer without the brewery name\n",
    "- **ba_brewery_id**: 10093 - Unique ID for the brewery\n",
    "- **ba_brewery_name**: Strangford Lough Brewing Company Ltd - Name of the brewery\n",
    "- **ba_bros_score**: 80.0 - The Bros Score is the average score given by the two brothers who founded BeerAdvocate\n",
    "- **ba_nbr_matched_valid_ratings**: 59\n",
    "- **ba_nbr_ratings**: 75 - The number of ratings for the beer\n",
    "- **ba_nbr_reviews**: 59 - The number of reviews for the beer\n",
    "- **ba_style**: English Pale Ale - The style of the beer\n",
    "- **ba_zscore**: -0.649167 - Indicates how many standard deviations a data point is from the mean of the dataset.\n",
    "\n",
    "## Dataset: RateBeer\n",
    "\n",
    "- **rb_abv**: 4.8 - Percentage alcohol\n",
    "- **rb_avg**: 2.79\n",
    "- **rb_avg_computed**: 2.923596\n",
    "- **rb_avg_matched_valid_ratings**: 2.923596\n",
    "- **rb_beer_id**: 37923 - Unique ID for the beer\n",
    "- **rb_beer_name**: Strangford Lough Legbiter - Name of the beer\n",
    "- **rb_beer_wout_brewery_name**: Legbiter - Name of the beer without the brewery name\n",
    "- **rb_brewery_id**: 4959 - Unique ID for the brewery\n",
    "- **rb_brewery_name**: Strangford Lough - Name of the brewery\n",
    "- **rb_nbr_matched_valid_ratings**: 89\n",
    "- **rb_nbr_ratings**: 89 - The number of reviews for the beer\n",
    "- **rb_overall_score**: 23.0 - The overall rating (out of 100)\n",
    "- **rb_style**: Golden Ale/Blond Ale - The style of the beer\n",
    "- **rb_style_score**: 27.0 - The rating in this style category (out of 100)\n",
    "- **rb_zscore**: -0.698304 - Indicates how many standard deviations a data point is from the mean of the dataset.\n",
    "\n",
    "## Dataset: Matched Beer Data\n",
    "\n",
    "- **scores_diff**: 1.0\n",
    "- **scores_sim**: 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part I : Dataset initialization and loading into a pandas DataFrame "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#libraries :\n",
    "import os\n",
    "import tarfile\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "#functions :\n",
    "from src.scripts.exporter_csv_correct_format import export_csv_correct_format as csv_exporter\n",
    "from src.scripts.load_some_dataset_and_save_it_in_data_directory import extract_full_data as load_txt_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the list of filenames to be extracted\n",
    "filenames = [\"matched_beer_data.tar.gz\", \"BeerAdvocate.tar.gz\", \"RateBeer.tar.gz\"]\n",
    "base_directory = \"src/data\"\n",
    "\n",
    "# Loop through each filename in the list\n",
    "# for fname in filenames:\n",
    "#     # Create the extraction folder named data_{base_name}\n",
    "#     base_name = os.path.splitext(os.path.splitext(fname)[0])[0]  # Remove both .tar and .gz\n",
    "#     extract_folder = os.path.join(base_directory, f\"data_{base_name}\")\n",
    "    \n",
    "#     # Create the folder if it does not exist\n",
    "#     os.makedirs(extract_folder, exist_ok=True)\n",
    "    \n",
    "#     # Check the file extension and open the tar file accordingly\n",
    "#     if fname.endswith(\"tar.gz\"):\n",
    "#         with tarfile.open(fname, \"r:gz\") as tar:\n",
    "#             tar.extractall(path=extract_folder)  \n",
    "#             print(f\"Extracted all contents from {fname} to {extract_folder}\")\n",
    "#     elif fname.endswith(\"tar\"):\n",
    "#         with tarfile.open(fname, \"r:\") as tar:\n",
    "#             tar.extractall(path=extract_folder)\n",
    "#             print(f\"Extracted all contents from {fname} to {extract_folder}\")\n",
    "#     else:\n",
    "#         print(f\"The file {fname} is not a recognized .tar.gz or .tar file.\")\n",
    "\n",
    "\n",
    "#3_ open data in pandas dataframe : \n",
    "    #3.1\n",
    "ba_beers = pd.read_csv(\"src/data/data_BeerAdvocate/beers.csv\")\n",
    "ba_breweries = pd.read_csv(\"src/data/data_BeerAdvocate/breweries.csv\")\n",
    "ba_users = pd.read_csv(\"src/data/data_BeerAdvocate/users.csv\")\n",
    "ba_ratings = pd.read_csv(\"src/data/data_BeerAdvocate/ratings.csv\")\n",
    "ba_reviews = pd.read_csv(\"src/data/data_BeerAdvocate/reviews.csv\")\n",
    "\n",
    "    #3.2\n",
    "rb_beers = pd.read_csv(\"src/data/data_RateBeer/beers.csv\")\n",
    "rb_breweries = pd.read_csv(\"src/data/data_RateBeer/breweries.csv\")\n",
    "rb_users = pd.read_csv(\"src/data/data_RateBeer/users.csv\")\n",
    "rb_ratings = pd.read_csv(\"src/data/data_RateBeer/ratings.csv\")\n",
    "rb_reviews = pd.read_csv(\"src/data/data_RateBeer/reviews.csv\")\n",
    "\n",
    "    #3.3 : we will mostly use this files, since they have fusionned the data from the ratebeer and beeradvocate datasets\n",
    "matched_beers = pd.read_csv(\"src/data/data_matched_beer_data/beers.csv\", header=[0, 1])\n",
    "matched_breweries = pd.read_csv(\"src/data/data_matched_beer_data/breweries.csv\", header=[0, 1])\n",
    "matched_ratings = pd.read_csv(\"src/data/data_matched_beer_data/ratings.csv\", header=[0, 1])\n",
    "matched_users_approx = pd.read_csv(\"src/data/data_matched_beer_data/users_approx.csv\", header=[0, 1])\n",
    "matched_users = pd.read_csv(\"src/data/data_matched_beer_data/users.csv\", header=[0, 1])\n",
    "\n",
    "    #3.3.1 : flatten the columns for easier access\n",
    "matched_beers.columns = ['_'.join(col).strip() for col in matched_beers.columns.values]\n",
    "matched_breweries.columns = ['_'.join(col).strip() for col in matched_breweries.columns.values]\n",
    "matched_ratings.columns = ['_'.join(col).strip() for col in matched_ratings.columns.values]\n",
    "matched_users_approx.columns = ['_'.join(map(str, col)).strip() for col in matched_users_approx.columns.values]\n",
    "matched_users.columns = ['_'.join(col).strip() for col in matched_users.columns.values]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Script to transform .txt data into .csv data for ease of use (takes time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to src/data/data_BeerAdvocate/ratings.csv\n"
     ]
    }
   ],
   "source": [
    "# #convert txt to csv by keeping only the columns we need\n",
    "# # Define file paths and column names\n",
    "# input_file_path = 'src/data/data_BeerAdvocate/ratings.txt'\n",
    "# output_file_path = 'src/data/data_BeerAdvocate/ratings.csv'\n",
    "# columns = [\n",
    "#     'beer_name', 'beer_id', 'brewery_name', 'brewery_id', 'style', 'abv', 'date',\n",
    "#     'user_name', 'user_id', 'appearance', 'aroma', 'palate', 'taste', \n",
    "#     'overall', 'rating'\n",
    "# ]  # we exclude \"text\" and \"review\" \n",
    "\n",
    "# def parse_entry(lines):\n",
    "#     entry = {}\n",
    "#     for line in lines:\n",
    "#         if ': ' in line:\n",
    "#             key, value = line.split(': ', 1)\n",
    "#             if key not in ['text', 'review']: \n",
    "#                 entry[key] = value.strip()\n",
    "#     return entry\n",
    "\n",
    "# data = []\n",
    "# entry_lines = []\n",
    "\n",
    "# with open(input_file_path, 'r', encoding='utf-8') as file:\n",
    "#     for line in file:\n",
    "#         if line.strip():  \n",
    "#             entry_lines.append(line.strip())\n",
    "#         else:\n",
    "#             if entry_lines:  \n",
    "#                 data.append(parse_entry(entry_lines))\n",
    "#                 entry_lines = []\n",
    "\n",
    "#     if entry_lines:\n",
    "#         data.append(parse_entry(entry_lines))\n",
    "\n",
    "\n",
    "# df = pd.DataFrame(data, columns=columns)\n",
    "# df.to_csv(output_file_path, index=False, encoding='utf-8')\n",
    "\n",
    "# print(f\"Data saved to {output_file_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Inspection of the data : Most reviewed beer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOP 1 : The beer '\u001b[1mTrappistes Rochefort 10\u001b[0m', brewed by '\u001b[1mBrasserie de Rochefort\u001b[0m' from, \u001b[1mBelgium\u001b[0m  is of style '\u001b[1mQuadrupel (Quad)\u001b[0m' and has been reviewed by '\u001b[1m14500\u001b[0m' persons with an average grade of '\u001b[1m4.44\u001b[0m' .\n",
      "TOP 2 : The beer '\u001b[1mBrooklyn Black Chocolate Stout\u001b[0m', brewed by '\u001b[1mBrooklyn Brewery\u001b[0m' from, \u001b[1mUnited States, New York\u001b[0m  is of style '\u001b[1mRussian Imperial Stout\u001b[0m' and has been reviewed by '\u001b[1m10078\u001b[0m' persons with an average grade of '\u001b[1m4.10\u001b[0m' .\n",
      "TOP 3 : The beer '\u001b[1mAleSmith Speedway Stout\u001b[0m', brewed by '\u001b[1mAleSmith Brewing Company\u001b[0m' from, \u001b[1mUnited States, California\u001b[0m  is of style '\u001b[1mAmerican Double / Imperial Stout\u001b[0m' and has been reviewed by '\u001b[1m9806\u001b[0m' persons with an average grade of '\u001b[1m4.36\u001b[0m' .\n",
      "TOP 4 : The beer '\u001b[1mDelirium Tremens\u001b[0m', brewed by '\u001b[1mBrouwerij Huyghe\u001b[0m' from, \u001b[1mBelgium\u001b[0m  is of style '\u001b[1mBelgian Strong Pale Ale\u001b[0m' and has been reviewed by '\u001b[1m9103\u001b[0m' persons with an average grade of '\u001b[1m3.95\u001b[0m' .\n",
      "TOP 5 : The beer '\u001b[1mBlind Pig IPA\u001b[0m', brewed by '\u001b[1mRussian River Brewing Company\u001b[0m' from, \u001b[1mUnited States, California\u001b[0m  is of style '\u001b[1mAmerican IPA\u001b[0m' and has been reviewed by '\u001b[1m7175\u001b[0m' persons with an average grade of '\u001b[1m4.29\u001b[0m' .\n"
     ]
    }
   ],
   "source": [
    "#1. Most reviewed beers and average grade : \n",
    "matched_beers['rb_and_ba_total_nbr_ratings'] = matched_beers['rb_nbr_ratings'] + matched_beers['ba_nbr_ratings']\n",
    "matched_beers['rb_and_ba_total_ratings'] = (matched_beers['rb_avg_computed']*matched_beers['rb_nbr_ratings'] + matched_beers['ba_avg_computed']*matched_beers['ba_nbr_ratings'])/matched_beers['rb_and_ba_total_nbr_ratings']\n",
    "\n",
    "\n",
    "# Merge to add 'country' column to matched_beers\n",
    "matched_beers = pd.merge(\n",
    "    matched_beers,matched_breweries[['rb_id', 'rb_location']],\n",
    "    left_on=['rb_brewery_id'],   # Columns in matched_beers\n",
    "    right_on=['rb_id'],  # Columns in matched_breweries\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "top_beers = matched_beers.sort_values(\n",
    "        by=['rb_and_ba_total_nbr_ratings'],ascending=False\n",
    "    ).head(5)\n",
    "\n",
    "# Print all\n",
    "i = 1\n",
    "for _, row in top_beers[['ba_beer_name', 'ba_brewery_name', 'ba_style', 'rb_and_ba_total_nbr_ratings', 'rb_and_ba_total_ratings', 'rb_location']].iterrows():\n",
    "    print(f\"TOP {i} : The beer '\\033[1m{row['ba_beer_name']}\\033[0m', brewed by '\\033[1m{row['ba_brewery_name']}\\033[0m' from, \\033[1m{row['rb_location']}\\033[0m \"\n",
    "          f\" is of style '\\033[1m{row['ba_style']}\\033[0m' and has been reviewed by '\\033[1m{row['rb_and_ba_total_nbr_ratings']}\\033[0m' persons with an average grade of '\\033[1m{row['rb_and_ba_total_ratings']:.2f}\\033[0m' .\")\n",
    "    i+=1\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3 : Most reviewed brewery."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOP 1: The brewery '\u001b[1mBrooklyn Brewery\u001b[0m' from '\u001b[1mUnited States, New York\u001b[0m' has been reviewed by '\u001b[1m37242\u001b[0m' persons with an average grade of '\u001b[1m3.78\u001b[0m'.\n",
      "TOP 2: The brewery '\u001b[1mRussian River Brewing Company\u001b[0m' from '\u001b[1mUnited States, California\u001b[0m' has been reviewed by '\u001b[1m31653\u001b[0m' persons with an average grade of '\u001b[1m4.18\u001b[0m'.\n",
      "TOP 3: The brewery '\u001b[1mMaine Beer Company\u001b[0m' from '\u001b[1mUnited States, Maine\u001b[0m' has been reviewed by '\u001b[1m25561\u001b[0m' persons with an average grade of '\u001b[1m4.21\u001b[0m'.\n",
      "TOP 4: The brewery '\u001b[1mWeyerbacher Brewing Co.\u001b[0m' from '\u001b[1mUnited States, Pennsylvania\u001b[0m' has been reviewed by '\u001b[1m24831\u001b[0m' persons with an average grade of '\u001b[1m3.66\u001b[0m'.\n",
      "TOP 5: The brewery '\u001b[1mBrouwerij Huyghe\u001b[0m' from '\u001b[1mBelgium\u001b[0m' has been reviewed by '\u001b[1m22184\u001b[0m' persons with an average grade of '\u001b[1m3.73\u001b[0m'.\n"
     ]
    }
   ],
   "source": [
    "#Step 2 : Most reviewed breweries and average grade :\n",
    "\n",
    "# Step 1: Calculate the weighted grades for each beer\n",
    "matched_beers['ba_prod_grade_nbr'] = matched_beers['ba_avg_computed'] * matched_beers['ba_nbr_ratings']\n",
    "matched_beers['rb_prod_grade_nbr'] = matched_beers['rb_avg_computed'] * matched_beers['rb_nbr_ratings']\n",
    "\n",
    "# Step 2: Group by brewery to get total weighted grades and ratings counts\n",
    "recap_breweries_info = (\n",
    "    matched_beers\n",
    "    .groupby('ba_brewery_id')[['ba_prod_grade_nbr', 'rb_prod_grade_nbr', 'ba_nbr_ratings', 'rb_nbr_ratings']]\n",
    "    .sum()\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Step 3: Calculate the average grade for each brewery\n",
    "recap_breweries_info['avg_grade'] = (\n",
    "    (recap_breweries_info['ba_prod_grade_nbr'] + recap_breweries_info['rb_prod_grade_nbr']) / \n",
    "    (recap_breweries_info['ba_nbr_ratings'] + recap_breweries_info['rb_nbr_ratings'])\n",
    ")\n",
    "\n",
    "# Step 4: Calculate total ratings count per brewery\n",
    "recap_breweries_info['total_nbr_ratings'] = recap_breweries_info['ba_nbr_ratings'] + recap_breweries_info['rb_nbr_ratings']\n",
    "\n",
    "# Step 5: Select only the final columns and sort by total ratings\n",
    "recap_breweries_info = (\n",
    "    recap_breweries_info[['ba_brewery_id', 'avg_grade', 'total_nbr_ratings']]\n",
    "    .sort_values(by='total_nbr_ratings', ascending=False)\n",
    ")\n",
    "\n",
    "# Step 6: Merge with brewery information to add name and location\n",
    "recap_breweries_info = pd.merge(\n",
    "    recap_breweries_info,\n",
    "    matched_breweries[['ba_id', 'ba_name', 'ba_location']],\n",
    "    left_on='ba_brewery_id',  \n",
    "    right_on='ba_id',           \n",
    "    how=\"left\"\n",
    ").drop(columns=['ba_id'])  # Drop the 'ba_id' column\n",
    "\n",
    "# Print each brewery's information\n",
    "i = 1\n",
    "for _, row in recap_breweries_info[['ba_brewery_id', 'ba_name', 'ba_location', 'total_nbr_ratings', 'avg_grade']].iterrows():\n",
    "    print(f\"TOP {i}: The brewery '\\033[1m{row['ba_name']}\\033[0m' from '\\033[1m{row['ba_location']}\\033[0m' \"\n",
    "          f\"has been reviewed by '\\033[1m{row['total_nbr_ratings']}\\033[0m' persons with an average grade of '\\033[1m{row['avg_grade']:.2f}\\033[0m'.\")\n",
    "    i += 1\n",
    "    if i > 5: break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In these first results, we can see a strong USA presence in the number of reviews for the beers and breweries, followed by Belgium. This leads us to wonder if there is an USA bias."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2b : add of dataset : Beer consumption per country from wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "beer_consumption_country_wikipedia = pd.read_csv(\"src/data/Data_consumption_per_country/List_of_countries_by_beer_consumption_per_capita_1.csv\")\n",
    "beer_consumption_country_wikipedia = beer_consumption_country_wikipedia.drop(columns=['2018\\nchange\\n(litres per year)', 'Year', 'Sources'])\n",
    "beer_consumption_country_wikipedia['Country'] = beer_consumption_country_wikipedia['Country'].str.replace(' *', '', regex=False)\n",
    "beer_consumption_country_wikipedia.rename(\n",
    "    columns={'Consumption\\nper capita\\n(litres per year)': 'consumption_per_inhabitant_L_per_year(wikipedia)'}, \n",
    "    inplace=True)\n",
    "beer_consumption_country_wikipedia.rename(\n",
    "    columns={'Total national\\nconsumption\\n(million litres\\nper year)': 'consumption_per_country_millionL_per_year(wikipedia)'}, \n",
    "    inplace=True)\n",
    "beer_consumption_country_wikipedia['consumption_per_country_millionL_per_year(wikipedia)'] = beer_consumption_country_wikipedia['consumption_per_country_millionL_per_year(wikipedia)'].str.replace(',', '', regex=False).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot The total consumption per country\n",
    "    #sort in ascending order\n",
    "# create the pyplot figure (with custom axis because huge usa biais)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Analysis of Customer Identity and origin\n",
    "\n",
    "In this section, we will analyze the identity of the customers by examining the number of reviewers per country in percentage and their average grade. This will help us understand the distribution and behavior of beer reviewers across different regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          country  num_users  avg_nbr_ratings\n",
      "192     United States, California    14442.0        68.674491\n",
      "225   United States, Pennsylvania    10321.0        86.017053\n",
      "219       United States, New York     8784.0        73.034950\n",
      "200       United States, Illinois     8272.0        89.258341\n",
      "208  United States, Massachusetts     7332.0        63.912029\n",
      "..                            ...        ...              ...\n",
      "184                        Tuvalu        1.0         1.000000\n",
      "183                  Turkmenistan        1.0        69.000000\n",
      "68                      Greenland        1.0       374.000000\n",
      "66                      Gibraltar        1.0         1.000000\n",
      "168                         Sudan        1.0         3.000000\n",
      "\n",
      "[250 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "#3. Now we deep into the identity of the customers, first by analyzing the number of reviewers per country in percentage and then by analyzing their average grade\n",
    "# Step 1: Count the number of users per country from both ba_users and rb_users\n",
    "users_per_country = ba_users['location'].value_counts().reset_index()\n",
    "users_per_country.columns = ['country', 'num_users_ba']\n",
    "\n",
    "users_per_country2 = rb_users['location'].value_counts().reset_index()\n",
    "users_per_country2.columns = ['country', 'num_users_rb']\n",
    "\n",
    "# Combine the user counts from both datasets\n",
    "total_users_per_country = pd.merge(users_per_country, users_per_country2, on='country', how='outer').fillna(0)\n",
    "total_users_per_country['num_users'] = total_users_per_country['num_users_ba'] + total_users_per_country['num_users_rb']\n",
    "\n",
    "# Step 2: Calculate the average number of ratings per country from both ba_users and rb_users\n",
    "avg_ratings_ba = ba_users.groupby('location')['nbr_ratings'].mean().reset_index()\n",
    "avg_ratings_ba.columns = ['country', 'avg_nbr_ratings_ba']\n",
    "\n",
    "avg_ratings_rb = rb_users.groupby('location')['nbr_ratings'].mean().reset_index()\n",
    "avg_ratings_rb.columns = ['country', 'avg_nbr_ratings_rb']\n",
    "\n",
    "# Step 3: Merge the average ratings from both datasets and calculate the combined average\n",
    "avg_ratings_per_country = pd.merge(avg_ratings_ba, avg_ratings_rb, on='country', how='outer').fillna(0)\n",
    "\n",
    "# Calculate the weighted average number of ratings\n",
    "avg_ratings_per_country = pd.merge(avg_ratings_per_country, total_users_per_country[['country', 'num_users_ba', 'num_users_rb']], on='country', how='left')\n",
    "avg_ratings_per_country['avg_nbr_ratings'] = (\n",
    "    (avg_ratings_per_country['avg_nbr_ratings_ba'] * avg_ratings_per_country['num_users_ba']) + \n",
    "    (avg_ratings_per_country['avg_nbr_ratings_rb'] * avg_ratings_per_country['num_users_rb'])\n",
    ") / (avg_ratings_per_country['num_users_ba'] + avg_ratings_per_country['num_users_rb'])\n",
    "\n",
    "# Step 4: Create the final country analysis table\n",
    "country_analysis = pd.merge(\n",
    "    total_users_per_country[['country', 'num_users']],\n",
    "    avg_ratings_per_country[['country', 'avg_nbr_ratings']],\n",
    "    on='country', \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Sort the results by the total number of users\n",
    "country_analysis = country_analysis.sort_values(by='num_users', ascending=False)\n",
    "\n",
    "# Display the result\n",
    "print(country_analysis)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                      country  num_users  avg_nbr_ratings\n",
      "200                             United States   140078.0        75.518561\n",
      "0                                      Canada     6579.0       124.791762\n",
      "1                                     England     3525.0       143.918014\n",
      "2                                   Australia     1996.0        70.682365\n",
      "3                                      Poland     1765.0       118.710482\n",
      "..                                        ...        ...              ...\n",
      "172  South Georgia and South Sandwich Islands        1.0        16.000000\n",
      "173                           Solomon Islands        1.0         3.000000\n",
      "174                                  Anguilla        1.0         1.000000\n",
      "175                          Falkland Islands        1.0         1.000000\n",
      "171                                     Yemen        1.0         2.000000\n",
      "\n",
      "[201 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Function to remove all entrie containing \"United States\" in the 'country' column and replace them with a single entry\n",
    "\n",
    "# This pattern captures any entry that starts with \"United States\" as a whole word\n",
    "us_rows = country_analysis[country_analysis['country'].str.contains(r\"\\bUnited States\\b\", case=False, na=False)]\n",
    "\n",
    "#Calculate product of num_users and avg_nbr_ratings for all \"United States\" entries\n",
    "total_product_ratings_time_population = (us_rows['num_users'] * us_rows['avg_nbr_ratings']).sum()\n",
    "\n",
    "#Sum the total nbr of users (reviews) for all \"United States\" entries\n",
    "total_nbr_users = us_rows['num_users'].sum()\n",
    "\n",
    "# Remove the rows containing \"United States\"\n",
    "country_info = country_analysis[~country_analysis['country'].str.contains(r\"\\bUnited States\\b\", case=False, na=False)]\n",
    "\n",
    "# Creates a new single row for the USA entry\n",
    "new_row = pd.DataFrame({\n",
    "    'country': ['United States'],\n",
    "    'num_users': [total_nbr_users],\n",
    "    'avg_nbr_ratings': [total_product_ratings_time_population / total_nbr_users]  # Calculates average ratings\n",
    "})\n",
    "\n",
    "#summaries all the infos in the country_info dataframe\n",
    "country_info = pd.concat([country_info, new_row], ignore_index=True) \n",
    "country_info = country_info.sort_values(by='num_users', ascending=False)\n",
    "\n",
    "# Display the modified DataFrame\n",
    "print(country_info)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48\n"
     ]
    }
   ],
   "source": [
    "#Now we will add the information about the population to the country_info dataframe \n",
    "countries_population = pd.read_csv(\"src/data/Data_Countries_population/countries_population.csv\") #taken from world bank group\n",
    "countries_population2010 = countries_population[['Country Name', '2010']] #since the data represents the ratings from 2001 to 2017, we will use the 2010 year as a reference.\n",
    "\n",
    "country_analysis2 = pd.merge(country_info, countries_population2010[['Country Name', '2010']], left_on='country', right_on='Country Name', how='left')\n",
    "\n",
    "country_analysis2 = country_analysis2.drop(columns=['Country Name'])\n",
    "#Now we will will count the number of Nan in the 2010 column, which represents the countries that have a slightly different name in the world bank group dataset\n",
    "#we will rename them by hand in the world bank group dataset.\n",
    "\n",
    "# Count the number of NaN values in the '2010' column\n",
    "num_nan_2010 = country_analysis2['2010'].isnull().sum()\n",
    "print (num_nan_2010)\n",
    "# Note: We reduced the NaN values to 48. The remaining \"countries\" were left because most of them are small regions that had to be attached to bigger ones because of \n",
    "# geopolitical reasons and others were small countries/islands with a low user counts (max 10), \n",
    "# making their impact on the analysis negligible.\n",
    "country_analysis2 = country_analysis2.dropna()\n",
    "\n",
    "#rename the 2010 column to 'population_in_2010'\n",
    "country_analysis2 = country_analysis2.rename(columns={'2010': 'population_in_2010'})\n",
    "country_analysis2['percentage_reviewers_per_country'] = (country_analysis2['num_users'] / country_analysis2['population_in_2010']) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# add brewery info to \"country_analysis2\" dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             country  num_users  avg_nbr_ratings  population_in_2010  \\\n",
      "0      United States   140078.0        75.518561         309327143.0   \n",
      "1             Canada     6579.0       124.791762          34005902.0   \n",
      "2            England     3525.0       143.918014          62766365.0   \n",
      "3          Australia     1996.0        70.682365          22031750.0   \n",
      "4             Poland     1765.0       118.710482          38042794.0   \n",
      "..               ...        ...              ...                 ...   \n",
      "148             Togo        1.0         2.000000           6571855.0   \n",
      "149       Seychelles        1.0         1.000000             89770.0   \n",
      "150        Sri Lanka        1.0         1.000000          20668557.0   \n",
      "151     Saudi Arabia        1.0        64.000000          29411929.0   \n",
      "152  Solomon Islands        1.0         3.000000            540394.0   \n",
      "\n",
      "     percentage_reviewers_per_country  nbr_breweries  \n",
      "0                            0.045285        34288.0  \n",
      "1                            0.019347         4030.0  \n",
      "2                            0.005616         3731.0  \n",
      "3                            0.009060         1877.0  \n",
      "4                            0.004640         1844.0  \n",
      "..                                ...            ...  \n",
      "148                          0.000015            2.0  \n",
      "149                          0.001114            1.0  \n",
      "150                          0.000005            3.0  \n",
      "151                          0.000003            1.0  \n",
      "152                          0.000185            1.0  \n",
      "\n",
      "[153 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "#3.2 : add infos about the breweries to \"country_analysis2\", with the same method as to add the infos about the users\n",
    "# Step 1: Count the number of breweries per country from both ba and rb datasets\n",
    "breweries_per_country = ba_breweries['location'].value_counts().reset_index()\n",
    "breweries_per_country.columns = ['country', 'nbr_breweries_ba']\n",
    "breweries_per_country2 = rb_users['location'].value_counts().reset_index()\n",
    "breweries_per_country2.columns = ['country', 'nbr_breweries_rb']\n",
    "\n",
    "# Combine the breweries counts from both datasets\n",
    "total_breweries_per_country = pd.merge(breweries_per_country, breweries_per_country2, on='country', how='outer').fillna(0)\n",
    "total_breweries_per_country['nbr_breweries'] = total_breweries_per_country['nbr_breweries_ba'] + total_breweries_per_country['nbr_breweries_rb']\n",
    "\n",
    "# Step 2: remove the entries containing \"United States\" and replace them with a single entry\n",
    "# Identify all entries that start with \"United States\" as a whole word\n",
    "us_rows = total_breweries_per_country[total_breweries_per_country['country'].str.contains(r\"\\bUnited States\\b\", case=False, na=False)]\n",
    "\n",
    "# Calculate the total number of breweries for all \"United States\" entries\n",
    "total_nbr_breweries = us_rows['nbr_breweries'].sum()\n",
    "\n",
    "# Remove the original rows with \"United States\" states\n",
    "total_breweries_with_single_usa = total_breweries_per_country[~total_breweries_per_country['country'].str.contains(r\"\\bUnited States\\b\", case=False, na=False)]\n",
    "\n",
    "# Create a new single row for the combined \"United States\" entry\n",
    "new_row = pd.DataFrame({\n",
    "    'country': ['United States'],\n",
    "    'nbr_breweries': [total_nbr_breweries],\n",
    "    \n",
    "})\n",
    "\n",
    "# Concatenate the new row with the modified DataFrame\n",
    "total_breweries_with_single_usa = pd.concat([total_breweries_with_single_usa, new_row], ignore_index=True)\n",
    "total_breweries_with_single_usa = total_breweries_with_single_usa.sort_values(by='nbr_breweries', ascending=False)\n",
    "\n",
    "# step 3 : merge with country analysis2 : \n",
    "total_breweries_with_single_usa=total_breweries_with_single_usa.drop(columns=['nbr_breweries_ba', 'nbr_breweries_rb'])\n",
    "country_analysis2 = pd.merge(country_analysis2, total_breweries_with_single_usa, on='country', how='left')\n",
    "print(country_analysis2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## add wikipedia data to country_info2 dataframe to better normalise the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['log_consumption_per_country_millionL_per_year(wikipedia)'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m country_analysis3 \u001b[38;5;241m=\u001b[39m country_analysis3\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCountry\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m#Now we will will count the number of Nan in the 2010 column, which represents the countries that have a slightly different name in the world bank group dataset\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m country_analysis3 \u001b[38;5;241m=\u001b[39m country_analysis3\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlog_consumption_per_country_millionL_per_year(wikipedia)\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\tomra\\anaconda3\\envs\\python_env1\\Lib\\site-packages\\pandas\\core\\frame.py:5581\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   5433\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdrop\u001b[39m(\n\u001b[0;32m   5434\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   5435\u001b[0m     labels: IndexLabel \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5442\u001b[0m     errors: IgnoreRaise \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   5443\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   5444\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   5445\u001b[0m \u001b[38;5;124;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[0;32m   5446\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5579\u001b[0m \u001b[38;5;124;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[0;32m   5580\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 5581\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mdrop(\n\u001b[0;32m   5582\u001b[0m         labels\u001b[38;5;241m=\u001b[39mlabels,\n\u001b[0;32m   5583\u001b[0m         axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[0;32m   5584\u001b[0m         index\u001b[38;5;241m=\u001b[39mindex,\n\u001b[0;32m   5585\u001b[0m         columns\u001b[38;5;241m=\u001b[39mcolumns,\n\u001b[0;32m   5586\u001b[0m         level\u001b[38;5;241m=\u001b[39mlevel,\n\u001b[0;32m   5587\u001b[0m         inplace\u001b[38;5;241m=\u001b[39minplace,\n\u001b[0;32m   5588\u001b[0m         errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m   5589\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\tomra\\anaconda3\\envs\\python_env1\\Lib\\site-packages\\pandas\\core\\generic.py:4788\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4786\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m   4787\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 4788\u001b[0m         obj \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m_drop_axis(labels, axis, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m   4790\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[0;32m   4791\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[1;32mc:\\Users\\tomra\\anaconda3\\envs\\python_env1\\Lib\\site-packages\\pandas\\core\\generic.py:4830\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[1;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[0;32m   4828\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m   4829\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 4830\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m   4831\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mget_indexer(new_axis)\n\u001b[0;32m   4833\u001b[0m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[0;32m   4834\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\tomra\\anaconda3\\envs\\python_env1\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:7070\u001b[0m, in \u001b[0;36mIndex.drop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   7068\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[0;32m   7069\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 7070\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabels[mask]\u001b[38;5;241m.\u001b[39mtolist()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in axis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   7071\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m indexer[\u001b[38;5;241m~\u001b[39mmask]\n\u001b[0;32m   7072\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelete(indexer)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['log_consumption_per_country_millionL_per_year(wikipedia)'] not found in axis\""
     ]
    }
   ],
   "source": [
    "#add the information about the countries (beer_consumption_country_wikipedia) to the country_analysis2 dataframe \n",
    "\n",
    "country_analysis3 = pd.merge(country_analysis2, beer_consumption_country_wikipedia, left_on='country', right_on='Country', how='left')\n",
    "\n",
    "country_analysis3 = country_analysis3.drop(columns=['Country'])\n",
    "#Now we will will count the number of Nan in the 2010 column, which represents the countries that have a slightly different name in the world bank group dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(country_analysis3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add more informations, to get final version : filtered_country_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "# discard countries with less than 50 users\n",
    "filtered_country_info = country_analysis3[country_analysis3['num_users'] >= 50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot 1: Nbr of Users and population per Country (Log Scale)\n",
    "fig, ax1 = plt.subplots(figsize=(12, 6))\n",
    "# Plot Number of Users\n",
    "ax1.bar(filtered_country_info['country'], filtered_country_info['num_users'], color='skyblue', label='Number of Users')\n",
    "ax1.set_xlabel('Country')\n",
    "ax1.set_ylabel('Number of Users')\n",
    "ax1.set_yscale('log')  \n",
    "ax1.set_title('Number of Users and Population per Country (Log Scale)')\n",
    "ax1.tick_params(axis='x', rotation=90)\n",
    "# Plot also the total Population of the country\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(filtered_country_info['country'], filtered_country_info['population_in_2010'], color='green', marker='o', linestyle='--', label='Population (2010)')\n",
    "ax2.set_ylabel('Population in 2010')\n",
    "ax2.set_yscale('log') \n",
    "ax1.legend(loc='upper left')\n",
    "ax2.legend(loc='upper right')\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#Plot 2: Percentage of Reviewers per Country (Log Scale)\n",
    "ig, ax1 = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "ax1.bar(filtered_country_info['country'], filtered_country_info['num_users'], color='skyblue', label='Number of Users')\n",
    "ax1.set_xlabel('Country')\n",
    "ax1.set_ylabel('Number of Users')\n",
    "ax1.set_yscale('log')  \n",
    "ax1.set_title('Number of Users and Percentage of Users per Country (Log Scale)')\n",
    "ax1.tick_params(axis='x', rotation=90)\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(filtered_country_info['country'], filtered_country_info['percentage_reviewers_per_country'], color='green', marker='o', linestyle='--', label='Percentage of Reviewers')\n",
    "ax2.set_ylabel('Percentage of Reviewers')\n",
    "ax2.set_yscale('log') \n",
    "ax1.legend(loc='upper left')\n",
    "ax2.legend(loc='upper right')\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot 3: Average Number of Ratings per Country (Log Scale)\n",
    "filtered_country_info2 = filtered_country_info.sort_values(by='avg_nbr_ratings', ascending=False)\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(filtered_country_info2['country'], filtered_country_info2['avg_nbr_ratings'], color='salmon')\n",
    "plt.xlabel('Country')\n",
    "plt.ylabel('Average Number of Ratings')\n",
    "plt.title('Average Number of Ratings per Country (Log Scale)')\n",
    "plt.yscale('log')  # Set y-axis to log scale\n",
    "plt.xticks(rotation=90)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(country_analysis3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interactive Plot for country_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_exporter(country_analysis3, 'country_analysis3')\n",
    "csv_exporter(beer_consumption_country_wikipedia, 'wikipedia_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 1 :plot The consumption per inhabitant for each country\n",
    "fig1 = px.choropleth(beer_consumption_country_wikipedia, locations='Country', locationmode='country names', color='consumption_per_inhabitant_L_per_year(wikipedia)',\n",
    "                    hover_name='Country',color_continuous_scale=[(0, 'blue'),(0.5, 'yellow'), (1, 'red')],\n",
    "                    title='Beer Consumption per inhabitant (litres per year)')\n",
    "\n",
    "\n",
    "# Figure 2 : consumption_per_country_millionL_per_year(wikipedia)\n",
    "beer_consumption_country_wikipedia['log_consumption_per_country_millionL_per_year(wikipedia)'] = np.log1p(beer_consumption_country_wikipedia['consumption_per_country_millionL_per_year(wikipedia)'])\n",
    "\n",
    "fig2 = px.choropleth(\n",
    "    beer_consumption_country_wikipedia, locations='Country',locationmode='country names',\n",
    "    hover_name='consumption_per_country_millionL_per_year(wikipedia)',hover_data={'log_consumption_per_country_millionL_per_year(wikipedia)': False, 'consumption_per_country_millionL_per_year(wikipedia)': True},  # hover is the info displayer when the mouse is on the country\n",
    "    color='log_consumption_per_country_millionL_per_year(wikipedia)', color_continuous_scale=[(0, 'blue'),(0.5, 'yellow'), (1, 'red')],\n",
    "    title='total consumption per country millionL per year (Log Scale)',\n",
    ")\n",
    "\n",
    "fig2.update_coloraxes(#we manually add the values on the colarbar\n",
    "    colorbar_tickmode='array',\n",
    "    colorbar_tickvals=np.log1p([1, 100, 1000, 10000, 40000]),\n",
    "    colorbar_ticktext=['1', '100', '1000', '10,000', '40,000'],\n",
    "    colorbar_title='total consumption per country millionL per year (Log Scale)'\n",
    ")\n",
    "\n",
    "# Figure 3 : Number of Reviewers per Country for rb and ba dataset (Log Scale)\n",
    "country_analysis3['log_num_users'] = np.log1p(country_analysis3['num_users'])\n",
    "fig3 = px.choropleth(\n",
    "    country_analysis3,\n",
    "    locations='country',\n",
    "    locationmode='country names',\n",
    "    color='log_num_users',  #for the color we use the loged values as the usa biais is huge\n",
    "    hover_name='country',\n",
    "    hover_data={'log_num_users': False, 'num_users': True},  # hover is the info displayer when the mouse is on the country\n",
    "    color_continuous_scale=[(0, 'blue'),(0.5, 'yellow'), (1, 'red')],\n",
    "    title='Number of Reviewers per Country for rb and ba dataset (Log Scale)',\n",
    "    labels={'num_users': 'Number of Reviewers'}\n",
    ")\n",
    "\n",
    "fig3.update_coloraxes(\n",
    "    colorbar_tickmode='array',\n",
    "    colorbar_tickvals=np.log1p([1, 10, 100, 1000, 10000, 100000]),\n",
    "    colorbar_ticktext=['1', '10', '100', '1,000', '10,000', '100,000'],\n",
    "    colorbar_title='Number of Reviewers'\n",
    ")\n",
    "\n",
    "# Figure 4 : average nbr of reviews per country\n",
    "fig4 = px.choropleth(country_analysis3, locations='country', locationmode='country names', color='avg_nbr_ratings',\n",
    "                    hover_name='country',color_continuous_scale=[(0, 'blue'),(0.5, 'yellow'), (1, 'red')],\n",
    "                    title='Average number of ratings per country')\n",
    "\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(fig1.data[0])\n",
    "fig.add_trace(fig2.data[0].update(visible=False))\n",
    "fig.add_trace(fig3.data[0].update(visible=False))\n",
    "fig.add_trace(fig4.data[0].update(visible=False))\n",
    "\n",
    "# Initiallise a dictionary for each plot\n",
    "buttons = [\n",
    "    dict(label='Beer Consumption per inhabitant (litres per year)',\n",
    "         method='update',args=[{'visible': [True, False,False,False]},{'title': fig1.layout.title.text}]),\n",
    "    dict(label='consumption_per_country_millionL_per_year(wikipedia)',\n",
    "         method='update',args=[{'visible': [False, True,False,False]},{'title': fig2.layout.title.text}]),\n",
    "    dict(label='Number of Reviewers per Country for rb and ba dataset (Log Scale)',\n",
    "         method='update',args=[{'visible': [False, False,True,False]},\n",
    "               {'title': fig3.layout.title.text}]),\n",
    "    dict(label='Average number of ratings per country',\n",
    "         method='update',args=[{'visible': [False, False,False,True]},{'title': fig4.layout.title.text}])\n",
    "]\n",
    "#manually add dropdown menu\n",
    "fig.update_layout(\n",
    "    updatemenus=[dict(type='dropdown',x=0,y=1,showactive=True,active=0,buttons=buttons)],\n",
    "    width=1000,height=600\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We noticed some problem with the data, specifically concerning the average number of ratings per country. A bot has probably been used and fakes our data.\n",
    "![Sample Image](src/Photo/Problem_with_data.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#interractive camember plot using pyplot\n",
    "\n",
    "#first, we will create a new dataset only for this plot where we drop the small countries with less than 100\n",
    "filtered_country_info_plotA = filtered_country_info[country_info['num_users'] >= 1000]\n",
    "fig = px.pie(\n",
    "    filtered_country_info_plotA,\n",
    "    values='num_users',\n",
    "    names='country',\n",
    "    title='Percentage of Reviewers per country worldwide for the rb and the ba dataset',\n",
    "    labels={'country': 'Country', 'num_users': 'Number of Reviewers per countries population'}\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "#then we plot the same data but we normalise by the countries population\n",
    "filtered_country_info_plotA['normalized_nbr_reviewers'] = (filtered_country_info_plotA['num_users'] / filtered_country_info_plotA['population_in_2010'])*100 \n",
    "fig = px.pie(\n",
    "    filtered_country_info_plotA,\n",
    "    values='normalized_nbr_reviewers',\n",
    "    names='country',\n",
    "    title='Percentage of Reviewers per country worldwide for the rb and the ba dataset (normalized by population)',\n",
    "    labels={'country': 'Country', 'normalized_nbr_reviewers': 'Number of Reviewers'}\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(filtered_country_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(filtered_country_info2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bar plot with the data from wikipedia (less biased) with country_analysis3 of both the percentage of reviewers and the consumption per inhabitant\n",
    "#using plotly\n",
    "# Create the interactive plot (go is also from plotly but lower level)\n",
    "filtered_country_info2_plotA = filtered_country_info2.sort_values(by='consumption_per_inhabitant_L_per_year(wikipedia)', ascending=False)\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Bar(\n",
    "    x=filtered_country_info2_plotA['country'],\n",
    "    y=filtered_country_info2_plotA['percentage_reviewers_per_country'],\n",
    "    name='Percentage Reviewers per Country',\n",
    "    yaxis='y'\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Bar(\n",
    "    x=filtered_country_info2_plotA['country'],\n",
    "    y=filtered_country_info2_plotA['consumption_per_inhabitant_L_per_year(wikipedia)'],\n",
    "    name='Consumption per Inhabitant L per Year (Wikipedia)',\n",
    "    yaxis='y2'\n",
    "))\n",
    "fig.update_layout(\n",
    "    title=\"Comparison of Reviewers Percentage from both datasets and Consumption\",\n",
    "    xaxis=dict(title=\"Country\"),\n",
    "    yaxis=dict(title=\"Percentage Reviewers per Country\",side=\"left\"\n",
    "    ),\n",
    "    yaxis2=dict(title=\"Consumption per Inhabitant L per Year (Wikipedia)\",side=\"right\",overlaying=\"y\"  \n",
    "    ),\n",
    "    legend=dict(title=\"Legend\")\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the number of users as a percentage of their population, we can observe that the usa have a disproportionate share of users. This in turn, due the large population of the USA, leads to a overrepresentation of those users. This can explain why US beers and breweries have the most ratings.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3.1 : We can also examine the number of breweries in each country in relation to the number of customers from that country."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(country_analysis2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Furthermore, as we are a small startup, we would like to know the average number of reviews that breweries from a country can get, to understand the competition \n",
    "# in the market and if it's possible the easily become known in the market.\n",
    "\n",
    "# discard countries with less than 50 users\n",
    "filtered_country_info = country_analysis2[country_analysis2['num_users'] >= 50]\n",
    "# Scatter plot of nbr breweries vs. nbr of usersfor each country\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(filtered_country_info['num_users'], filtered_country_info['nbr_breweries'])\n",
    "\n",
    "# Add labels for each country \n",
    "for i, row in filtered_country_info.iterrows():\n",
    "    plt.text(row['num_users'], row['nbr_breweries'], row['country'])\n",
    "\n",
    "# log scale to handle wide ranges (mostly for the usa)\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "\n",
    "# Labels and title\n",
    "plt.xlabel('Number of Users (log scale)')\n",
    "plt.ylabel('Number of Breweries (log scale)')\n",
    "plt.title('Number of Breweries vs. Number of Users per Country')\n",
    "\n",
    "# Show plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume 'population_in_2010' column exists in your 'country_analysis2' DataFrame for each country\n",
    "# Filter countries with at least 50 users\n",
    "filtered_country_info = country_analysis2[country_analysis2['num_users'] >= 5]\n",
    "\n",
    "# Calculate users and breweries per million people to normalize by population\n",
    "filtered_country_info['users_per_million'] = (filtered_country_info['num_users'] / filtered_country_info['population_in_2010']) * 1e6\n",
    "filtered_country_info['breweries_per_million'] = (filtered_country_info['nbr_breweries'] / filtered_country_info['population_in_2010']) * 1e6\n",
    "\n",
    "# Scatter plot of breweries per million vs. users per million for each country\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(filtered_country_info['users_per_million'], filtered_country_info['breweries_per_million'], color='green')\n",
    "\n",
    "# Add labels for each country\n",
    "for i, row in filtered_country_info.iterrows():\n",
    "    plt.text(row['users_per_million'], row['breweries_per_million'], row['country'], fontsize=8)\n",
    "\n",
    "# Use log scale to handle wide ranges\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "\n",
    "# Labels and title\n",
    "plt.xlabel('nbr of users normalised by nbr of inhabitants per country (log scale)')\n",
    "plt.ylabel('nbr of Breweries normalised by nbr of inhabitants per country (log scale)')\n",
    "plt.title('normalised number of Breweries vs. normalised number of Users per Country')\n",
    "\n",
    "# Show plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_country_info = country_analysis2[country_analysis2['num_users'] >= 5]\n",
    "\n",
    "# Calculate users per million people to normalize by population\n",
    "filtered_country_info['norm_num_users'] = (filtered_country_info['num_users'] / filtered_country_info['population_in_2010']) \n",
    "\n",
    "# Sort values by users per million for better visualization and select the top 15 countries\n",
    "filtered_country_info = filtered_country_info.sort_values(by='norm_num_users', ascending=False).head(15)\n",
    "\n",
    "# Plot the pie chart of users per million\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.pie(\n",
    "    filtered_country_info['norm_num_users'], \n",
    "    labels=filtered_country_info['country'], \n",
    "    autopct='%1.1f%%',  #to have the percentages on the pie chart\n",
    "    startangle=140,\n",
    "    wedgeprops=dict(edgecolor='black')\n",
    ")\n",
    "\n",
    "# Title\n",
    "plt.title('Percentage of Users per Country Normalised by Population (Top 15)')\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART 4 : Time analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert date to datetime, keep only days\n",
    "ba_ratings['date'] = pd.to_datetime(ba_ratings['date'], origin='unix', unit='s').dt.date\n",
    "rb_ratings['date'] = pd.to_datetime(rb_ratings['date'], origin='unix', unit='s').dt.date\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5), sharey=True, sharex=True)\n",
    "#number of reviews per day\n",
    "daily_count_BA = ba_ratings['date'].value_counts().sort_index()\n",
    "#add 30 days moving average to smooth the curve\n",
    "rolling_avg_BA = daily_count_BA.rolling(window=30).mean()\n",
    "\n",
    "daily_count_RB = rb_ratings['date'].value_counts().sort_index()\n",
    "rolling_avg_RB = daily_count_RB.rolling(window=30).mean()\n",
    "\n",
    "axes[0].plot(daily_count_BA, alpha=0.5, label='Daily', color='blue')\n",
    "axes[0].plot(rolling_avg_BA, alpha=0.8, label='30-day moving average', color='orange')\n",
    "axes[0].set_title('Number of reviews per day - BeerAdvocate')\n",
    "axes[0].set_xlabel('Date')\n",
    "axes[0].set_ylabel('Number of reviews')\n",
    "axes[0].legend()\n",
    "\n",
    "axes[1].plot(daily_count_RB, alpha=0.5, label='Daily', color='blue')\n",
    "axes[1].plot(rolling_avg_RB, alpha=0.8, label='30-day moving average', color='orange')\n",
    "axes[1].set_title('Number of reviews per day - RateBeer')\n",
    "axes[1].set_xlabel('Date')\n",
    "axes[1].set_ylabel('Number of reviews')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#look at the evolution of the average grade over time\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5), sharey=True, sharex=True)\n",
    "\n",
    "#use moving average to smooth the curve\n",
    "ba_average_grade = ba_ratings.groupby('date')['rating'].mean().rolling(window=30).mean()\n",
    "rb_average_grade = rb_ratings.groupby('date')['rating'].mean().rolling(window=30).mean()\n",
    "\n",
    "axes[0].plot(ba_average_grade, color='blue')\n",
    "axes[0].set_title('Average grade per day - BeerAdvocate')\n",
    "axes[0].set_xlabel('Date')\n",
    "axes[0].set_ylabel('Average grade (out of 5)')\n",
    "axes[0].grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "axes[1].plot(rb_average_grade, color='blue')\n",
    "axes[1].set_title('Average grade per day - RateBeer')\n",
    "axes[1].set_xlabel('Date')\n",
    "axes[1].set_ylabel('Average grade(out of 20)')\n",
    "axes[1].grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate average ratings per style\n",
    "ba_avg_ratings = ba_ratings.groupby('style')['rating'].mean().sort_values()\n",
    "rb_avg_ratings = rb_ratings.groupby('style')['rating'].mean().sort_values()\n",
    "\n",
    "# Select top 30 and bottom 3 beer styles\n",
    "ba_combined_styles = pd.concat([ba_avg_ratings.head(3), pd.Series([np.nan], index=[\"...\"]), ba_avg_ratings.tail(30)])\n",
    "rb_combined_styles = pd.concat([rb_avg_ratings.head(3), pd.Series([np.nan], index=[\"...\"]), rb_avg_ratings.tail(30)])\n",
    "\n",
    "# Create subplots\n",
    "fig, axes = plt.subplots(1, 2, figsize=(20, 10), sharex=True)\n",
    "\n",
    "sns.barplot(x=ba_combined_styles.values, y=ba_combined_styles.index, ax=axes[0])\n",
    "axes[0].set_title('Top 30 and Bottom 3 Beer Styles by Average Rating - BeerAdvocate')\n",
    "axes[0].set_xlabel('Average Rating')\n",
    "axes[0].set_ylabel('Beer Style')\n",
    "axes[0].invert_yaxis() \n",
    "\n",
    "sns.barplot(x=rb_combined_styles.values, y=rb_combined_styles.index, ax=axes[1])\n",
    "axes[1].set_title('Top 30 and Bottom 3 Beer Styles by Average Rating - RateBeer')\n",
    "axes[1].set_xlabel('Average Rating')\n",
    "axes[1].set_ylabel('Beer Style')\n",
    "axes[1].invert_yaxis() \n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the number of reviews per style\n",
    "ba_number_of_reviews_per_style = ba_ratings['style'].value_counts().head(30)\n",
    "rb_number_of_reviews_per_style = rb_ratings['style'].value_counts().head(30)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(20, 10), sharex=True)\n",
    "\n",
    "sns.barplot(x=ba_number_of_reviews_per_style.values, y=ba_number_of_reviews_per_style.index, ax=axes[0])\n",
    "axes[0].set_title('Top 30 reviews per beer style - BeerAdvocate')\n",
    "axes[0].set_xlabel('Number of Reviews')\n",
    "axes[0].set_ylabel('Beer Style')\n",
    "axes[0].invert_yaxis() \n",
    "\n",
    "sns.barplot(x=rb_number_of_reviews_per_style.values, y=rb_number_of_reviews_per_style.index, ax=axes[1])\n",
    "axes[1].set_title('Top 30 reviews per beer style - RateBeer')\n",
    "axes[1].set_xlabel('Number of Reviews')\n",
    "axes[1].set_ylabel('Beer Style')\n",
    "axes[1].invert_yaxis() \n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a seasonal dataframe by keeping only the month and day\n",
    "ba_ratings['date'] = pd.to_datetime(ba_ratings['date'])\n",
    "ba_ratings['month_day'] = ba_ratings['date'].dt.strftime('%m-%d')\n",
    "\n",
    "rb_ratings['date'] = pd.to_datetime(rb_ratings['date'])\n",
    "rb_ratings['month_day'] = rb_ratings['date'].dt.strftime('%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the number of reviews per day of the year with a 7-day moving average\n",
    "ba_number_of_reviews_per_day = ba_ratings['month_day'].value_counts().sort_index().rolling(window=7).mean() \n",
    "rb_number_of_reviews_per_day = rb_ratings['month_day'].value_counts().sort_index().rolling(window=7).mean()\n",
    "\n",
    "plt.plot(ba_number_of_reviews_per_day, label='BeerAdvocate', color='blue')\n",
    "plt.plot(rb_number_of_reviews_per_day, label='RateBeer', color='orange')\n",
    "\n",
    "months = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "plt.xticks(ticks=range(0, len(ba_number_of_reviews_per_day), int(len(ba_number_of_reviews_per_day) / 11)), \n",
    "           labels=months)\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.title('Number of reviews per day of the year')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Number of reviews')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Look only at the top styles\n",
    "ba_styles_top = ba_ratings.groupby('style')['rating'].mean().sort_values().tail(5)\n",
    "rb_styles_top = rb_ratings.groupby('style')['rating'].mean().sort_values().tail(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ba_ratings_top = ba_ratings[ba_ratings['style'].isin(ba_styles_top.index)]\n",
    "ba_average_ratings_per_day = ba_ratings_top.groupby(['style', 'month_day'])['rating'].mean().unstack('style')\n",
    "ba_rolling_avg_top = ba_average_ratings_per_day.rolling(window=7).mean()\n",
    "\n",
    "plt.figure(figsize=(14, 7))\n",
    "for style in ba_styles_top.index:\n",
    "    plt.plot(ba_rolling_avg_top.index, ba_rolling_avg_top[style], label=style)\n",
    "\n",
    "months = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "plt.xticks(ticks=range(0, len(ba_rolling_avg_top), int(len(ba_rolling_avg_top) / 11)), labels=months)\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.title('7-Day Moving Average of Ratings for Top 5 Beer Styles per Day for BeerAdvocate')\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Average Rating')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rb_ratings_top = rb_ratings[rb_ratings['style'].isin(rb_styles_top.index)]\n",
    "rb_average_ratings_per_day = rb_ratings_top.groupby(['style', 'month_day'])['rating'].mean().unstack('style')\n",
    "rb_rolling_avg_top = rb_average_ratings_per_day.rolling(window=7).mean()\n",
    "\n",
    "plt.figure(figsize=(14, 7))\n",
    "for style in rb_styles_top.index:\n",
    "    plt.plot(rb_rolling_avg_top.index, rb_rolling_avg_top[style], label=style)\n",
    "\n",
    "months = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "plt.xticks(ticks=range(0, len(rb_rolling_avg_top), int(len(rb_rolling_avg_top) / 11)), labels=months)\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.title('7-Day Moving Average of Ratings for Top 5 Beer Styles per Day for RateBeer')\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Average Rating')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(beer_consumption_country_wikipedia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python_env1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
