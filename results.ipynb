{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#What information can help us answer the question : are newcommers welcomed in the beer market?\n",
    "# 1. The number of breweries that have been established in the last 5 years +list of these breweries\n",
    "# 2. The number of customer reviews for each of these breweries, which indicates the popularity of the brewery.\n",
    "# 3. Average rating of the beers from these breweries, which indicates the quality of the beer.\n",
    "# 4. A graph showing the number of total reviews with time to see if the number of reviews is increasing or decreasing.\n",
    "\n",
    "#what information can help us answer the question : parameters : \"Volume_Produced:\" ; \"Total_Sales:\" ; \"Quality_Score:\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#does price correlate with quality and rating?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = pd.read_csv(\"src/data/data_matched_beer_data/ratings.csv\")\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To do now : 1. number of reviews with time\n",
    "            #2. average grade evolution with time \n",
    "\n",
    "#Part 1 : Number of reviews with time\n",
    "\n",
    "# Convert the 'timestamp' column to a human-readable date format\n",
    "ratings['date_converted_to_classic'] = ratings['date'].apply(convert_timestamp_to_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted all contents from matched_beer_data.tar.gz to src/data\\data_matched_beer_data\n",
      "Extracted all contents from BeerAdvocate.tar.gz to src/data\\data_BeerAdvocate\n",
      "Extracted all contents from RateBeer.tar.gz to src/data\\data_RateBeer\n"
     ]
    }
   ],
   "source": [
    "#access to datasets \n",
    "import os\n",
    "import tarfile\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "    #0. info about datasets : \n",
    "    # 0.1. beers.csv: Contains information about the beers, such as the name, style, and brewery.\n",
    "        # 0.2. breweries.csv: Contains information about the breweries, such as the name and location.\n",
    "        # 0.3. reviews.csv: Contains information about the reviews, such as the beer ID, user ID, and rating.\n",
    "        # 0.4. ratings.csv: Contains information about the ratings, such as the beer ID, user ID, and rating.\n",
    "        # 0.5. users.csv: Contains information about the users, such as the username and age.\n",
    "\n",
    "#Summary of Ratings : \n",
    "    #dataset : beeradvocate : \n",
    "        # ba_abv                                                                    4.8 : percentage alcohol\n",
    "        # ba_avg                                                                   3.45 : avg rating (out of 5) of the beer\n",
    "        # ba_avg_computed                                                      3.439867 : avg rating (out of 5) of the beer\n",
    "        # ba_avg_matched_valid_ratings                                         3.504068 : \n",
    "        # ba_ba_score                                                              80.0 : BA Score is the beer's overall score (out of 100) based on its ranking within its style category, based on a custon bayesian algorithm\n",
    "        # ba_beer_id                                                              19827 : unique id for the beer\n",
    "        # ba_beer_name                                                         Legbiter : name of the beer\n",
    "        # ba_beer_wout_brewery_name                                            Legbiter : name of the beer without the brewery name\n",
    "        # ba_brewery_id                                                           10093 : unique id for the brewery\n",
    "        # ba_brewery_name                          Strangford Lough Brewing Company Ltd : name of the brewery\n",
    "        # ba_bros_score                                                            80.0 : The Bros Score is the average score given by the two brothers who founded BeerAdvocate\n",
    "        # ba_nbr_matched_valid_ratings                                               59 : \n",
    "        # ba_nbr_ratings                                                             75 : (int): the number of ratings for the beer\n",
    "        # ba_nbr_reviews                                                             59 : (int): the number of reviews for the beer\n",
    "        # ba_style                                                     English Pale Ale : (str): the style of the beer\n",
    "        # ba_zscore                                                           -0.649167 : It indicates how many standard deviations a data point is from the mean of the dataset.\n",
    "                                       \n",
    "\n",
    "    #dataset : ratebeer : \n",
    "        # rb_abv                                                                    4.8 : percentage alcohol\n",
    "        # rb_avg                                                                   2.79 :\n",
    "        # rb_avg_computed                                                      2.923596 :\n",
    "        # rb_avg_matched_valid_ratings                                         2.923596 :\n",
    "        # rb_beer_id                                                              37923 : just a unique id for the beer\n",
    "        # rb_beer_name                                        Strangford Lough Legbiter : name of the beer\n",
    "        # rb_beer_wout_brewery_name                                            Legbiter : name of the beer without the brewery name\n",
    "        # rb_brewery_id                                                            4959 : unique id for the brewery\n",
    "        # rb_brewery_name                                              Strangford Lough : name of the brewery\n",
    "        # rb_nbr_matched_valid_ratings                                               89 :\n",
    "        # rb_nbr_ratings                                                             89 : (int): the number of reviews for the beer\n",
    "        # rb_overall_score                                                         23.0 : (int): the overall rating (out of 100)\n",
    "        # rb_style                                                 Golden Ale/Blond Ale : (str): the style of the beer\n",
    "        # rb_style_score                                                           27.0 : (int): the rating in this style category (out of 100)\n",
    "        # rb_zscore                                                           -0.698304 : It indicates how many standard deviations a data point is from the mean of the dataset.\n",
    "        \n",
    "    #dataset : matched_beer_data :   \n",
    "        # scores_diff                                                               1.0\n",
    "        # scores_sim                                                                1.0\n",
    "\n",
    "import os\n",
    "import tarfile\n",
    "\n",
    "# Define the list of filenames to be extracted\n",
    "filenames = [\"matched_beer_data.tar.gz\", \"BeerAdvocate.tar.gz\", \"RateBeer.tar.gz\"]\n",
    "base_directory = \"src/data\"\n",
    "\n",
    "# Loop through each filename in the list\n",
    "for fname in filenames:\n",
    "    # Create the extraction folder named data_{base_name}\n",
    "    base_name = os.path.splitext(os.path.splitext(fname)[0])[0]  # Remove both .tar and .gz\n",
    "    extract_folder = os.path.join(base_directory, f\"data_{base_name}\")\n",
    "    \n",
    "    # Create the folder if it does not exist\n",
    "    os.makedirs(extract_folder, exist_ok=True)\n",
    "    \n",
    "    # Check the file extension and open the tar file accordingly\n",
    "    if fname.endswith(\"tar.gz\"):\n",
    "        with tarfile.open(fname, \"r:gz\") as tar:\n",
    "            tar.extractall(path=extract_folder)  \n",
    "            print(f\"Extracted all contents from {fname} to {extract_folder}\")\n",
    "    elif fname.endswith(\"tar\"):\n",
    "        with tarfile.open(fname, \"r:\") as tar:\n",
    "            tar.extractall(path=extract_folder)\n",
    "            print(f\"Extracted all contents from {fname} to {extract_folder}\")\n",
    "    else:\n",
    "        print(f\"The file {fname} is not a recognized .tar.gz or .tar file.\")\n",
    "\n",
    "\n",
    "\n",
    "#3_ open data in pandas dataframe : \n",
    "    #3.1\n",
    "ba_beers = pd.read_csv(\"src/data/data_BeerAdvocate/beers.csv\")\n",
    "ba_breweries = pd.read_csv(\"src/data/data_BeerAdvocate/breweries.csv\")\n",
    "ba_users = pd.read_csv(\"src/data/data_BeerAdvocate/users.csv\")\n",
    "\n",
    "    #3.2\n",
    "rb_beers = pd.read_csv(\"src/data/data_RateBeer/beers.csv\")\n",
    "rb_breweries = pd.read_csv(\"src/data/data_RateBeer/breweries.csv\")\n",
    "rb_users = pd.read_csv(\"src/data/data_RateBeer/users.csv\")\n",
    "\n",
    "    #3.3 : we will mostly use this files, since they have fusionned the data from the ratebeer and beeradvocate datasets\n",
    "matched_beers = pd.read_csv(\"src/data/data_matched_beer_data/beers.csv\", header=[0, 1])\n",
    "matched_breweries = pd.read_csv(\"src/data/data_matched_beer_data/breweries.csv\", header=[0, 1])\n",
    "matched_ratings = pd.read_csv(\"src/data/data_matched_beer_data/ratings.csv\", header=[0, 1])\n",
    "matched_users_approx = pd.read_csv(\"src/data/data_matched_beer_data/users_approx.csv\", header=[0, 1])\n",
    "matched_users = pd.read_csv(\"src/data/data_matched_beer_data/users.csv\", header=[0, 1])\n",
    "    #3.3.1 : flatten the columns for easier access\n",
    "matched_beers.columns = ['_'.join(col).strip() for col in matched_beers.columns.values]\n",
    "matched_breweries.columns = ['_'.join(col).strip() for col in matched_breweries.columns.values]\n",
    "matched_ratings.columns = ['_'.join(col).strip() for col in matched_ratings.columns.values]\n",
    "matched_users_approx.columns = ['_'.join(map(str, col)).strip() for col in matched_users_approx.columns.values]\n",
    "matched_users.columns = ['_'.join(col).strip() for col in matched_users.columns.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOP 1 : The beer '\u001b[1mTrappistes Rochefort 10\u001b[0m', brewed by '\u001b[1mBrasserie de Rochefort\u001b[0m' from, \u001b[1mBelgium\u001b[0m  is of style '\u001b[1mQuadrupel (Quad)\u001b[0m' and has been reviewed by '\u001b[1m14500\u001b[0m' persons with an average grade of '\u001b[1m4.44\u001b[0m' .\n",
      "TOP 2 : The beer '\u001b[1mBrooklyn Black Chocolate Stout\u001b[0m', brewed by '\u001b[1mBrooklyn Brewery\u001b[0m' from, \u001b[1mUnited States, New York\u001b[0m  is of style '\u001b[1mRussian Imperial Stout\u001b[0m' and has been reviewed by '\u001b[1m10078\u001b[0m' persons with an average grade of '\u001b[1m4.10\u001b[0m' .\n",
      "TOP 3 : The beer '\u001b[1mAleSmith Speedway Stout\u001b[0m', brewed by '\u001b[1mAleSmith Brewing Company\u001b[0m' from, \u001b[1mUnited States, California\u001b[0m  is of style '\u001b[1mAmerican Double / Imperial Stout\u001b[0m' and has been reviewed by '\u001b[1m9806\u001b[0m' persons with an average grade of '\u001b[1m4.36\u001b[0m' .\n",
      "TOP 4 : The beer '\u001b[1mDelirium Tremens\u001b[0m', brewed by '\u001b[1mBrouwerij Huyghe\u001b[0m' from, \u001b[1mBelgium\u001b[0m  is of style '\u001b[1mBelgian Strong Pale Ale\u001b[0m' and has been reviewed by '\u001b[1m9103\u001b[0m' persons with an average grade of '\u001b[1m3.95\u001b[0m' .\n",
      "TOP 5 : The beer '\u001b[1mBlind Pig IPA\u001b[0m', brewed by '\u001b[1mRussian River Brewing Company\u001b[0m' from, \u001b[1mUnited States, California\u001b[0m  is of style '\u001b[1mAmerican IPA\u001b[0m' and has been reviewed by '\u001b[1m7175\u001b[0m' persons with an average grade of '\u001b[1m4.29\u001b[0m' .\n"
     ]
    }
   ],
   "source": [
    "#Data exploration : \n",
    "\n",
    "    #1. Most reviewed beer.\n",
    "    #2. Most reviewed brewery.\n",
    "    #3. Most reviewers per country (in percentage)\n",
    "\n",
    "#1. Most reviewed beers and average grade : \n",
    "matched_beers['rb_and_ba_total_nbr_ratings'] = matched_beers['rb_nbr_ratings'] + matched_beers['ba_nbr_ratings']\n",
    "matched_beers['rb_and_ba_total_ratings'] = (matched_beers['rb_avg_computed']*matched_beers['rb_nbr_ratings'] + matched_beers['ba_avg_computed']*matched_beers['ba_nbr_ratings'])/matched_beers['rb_and_ba_total_nbr_ratings']\n",
    "\n",
    "\n",
    "# Merge to add 'country' column to matched_beers\n",
    "matched_beers = pd.merge(\n",
    "    matched_beers,matched_breweries[['rb_id', 'rb_location']],\n",
    "    left_on=['rb_brewery_id'],   # Columns in matched_beers\n",
    "    right_on=['rb_id'],  # Columns in matched_breweries\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "top_beers = matched_beers.sort_values(\n",
    "        by=['rb_and_ba_total_nbr_ratings'],ascending=False\n",
    "    ).head(5)\n",
    "\n",
    "# Print all\n",
    "i = 1\n",
    "for _, row in top_beers[['ba_beer_name', 'ba_brewery_name', 'ba_style', 'rb_and_ba_total_nbr_ratings', 'rb_and_ba_total_ratings', 'rb_location']].iterrows():\n",
    "    print(f\"TOP {i} : The beer '\\033[1m{row['ba_beer_name']}\\033[0m', brewed by '\\033[1m{row['ba_brewery_name']}\\033[0m' from, \\033[1m{row['rb_location']}\\033[0m \"\n",
    "          f\" is of style '\\033[1m{row['ba_style']}\\033[0m' and has been reviewed by '\\033[1m{row['rb_and_ba_total_nbr_ratings']}\\033[0m' persons with an average grade of '\\033[1m{row['rb_and_ba_total_ratings']:.2f}\\033[0m' .\")\n",
    "    i+=1\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOP 1: The brewery '\u001b[1mBrooklyn Brewery\u001b[0m' from '\u001b[1mUnited States, New York\u001b[0m' has been reviewed by '\u001b[1m37242\u001b[0m' persons with an average grade of '\u001b[1m3.78\u001b[0m'.\n",
      "TOP 2: The brewery '\u001b[1mRussian River Brewing Company\u001b[0m' from '\u001b[1mUnited States, California\u001b[0m' has been reviewed by '\u001b[1m31653\u001b[0m' persons with an average grade of '\u001b[1m4.18\u001b[0m'.\n",
      "TOP 3: The brewery '\u001b[1mMaine Beer Company\u001b[0m' from '\u001b[1mUnited States, Maine\u001b[0m' has been reviewed by '\u001b[1m25561\u001b[0m' persons with an average grade of '\u001b[1m4.21\u001b[0m'.\n",
      "TOP 4: The brewery '\u001b[1mWeyerbacher Brewing Co.\u001b[0m' from '\u001b[1mUnited States, Pennsylvania\u001b[0m' has been reviewed by '\u001b[1m24831\u001b[0m' persons with an average grade of '\u001b[1m3.66\u001b[0m'.\n",
      "TOP 5: The brewery '\u001b[1mBrouwerij Huyghe\u001b[0m' from '\u001b[1mBelgium\u001b[0m' has been reviewed by '\u001b[1m22184\u001b[0m' persons with an average grade of '\u001b[1m3.73\u001b[0m'.\n"
     ]
    }
   ],
   "source": [
    "#Step 2 : Most reviewed breweries and average grade :\n",
    "\n",
    "# Step 1: Calculate the weighted grades for each beer\n",
    "matched_beers['ba_prod_grade_nbr'] = matched_beers['ba_avg_computed'] * matched_beers['ba_nbr_ratings']\n",
    "matched_beers['rb_prod_grade_nbr'] = matched_beers['rb_avg_computed'] * matched_beers['rb_nbr_ratings']\n",
    "\n",
    "# Step 2: Group by brewery to get total weighted grades and ratings counts\n",
    "recap_breweries_info = (\n",
    "    matched_beers\n",
    "    .groupby('ba_brewery_id')[['ba_prod_grade_nbr', 'rb_prod_grade_nbr', 'ba_nbr_ratings', 'rb_nbr_ratings']]\n",
    "    .sum()\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Step 3: Calculate the average grade for each brewery\n",
    "recap_breweries_info['avg_grade'] = (\n",
    "    (recap_breweries_info['ba_prod_grade_nbr'] + recap_breweries_info['rb_prod_grade_nbr']) / \n",
    "    (recap_breweries_info['ba_nbr_ratings'] + recap_breweries_info['rb_nbr_ratings'])\n",
    ")\n",
    "\n",
    "# Step 4: Calculate total ratings count per brewery\n",
    "recap_breweries_info['total_nbr_ratings'] = recap_breweries_info['ba_nbr_ratings'] + recap_breweries_info['rb_nbr_ratings']\n",
    "\n",
    "# Step 5: Select only the final columns and sort by total ratings\n",
    "recap_breweries_info = (\n",
    "    recap_breweries_info[['ba_brewery_id', 'avg_grade', 'total_nbr_ratings']]\n",
    "    .sort_values(by='total_nbr_ratings', ascending=False)\n",
    ")\n",
    "\n",
    "# Step 6: Merge with brewery information to add name and location\n",
    "recap_breweries_info = pd.merge(\n",
    "    recap_breweries_info,\n",
    "    matched_breweries[['ba_id', 'ba_name', 'ba_location']],\n",
    "    left_on='ba_brewery_id',  \n",
    "    right_on='ba_id',           \n",
    "    how=\"left\"\n",
    ").drop(columns=['ba_id'])  # Drop the 'ba_id' column\n",
    "\n",
    "# Print each brewery's information\n",
    "i = 1\n",
    "for _, row in recap_breweries_info[['ba_brewery_id', 'ba_name', 'ba_location', 'total_nbr_ratings', 'avg_grade']].iterrows():\n",
    "    print(f\"TOP {i}: The brewery '\\033[1m{row['ba_name']}\\033[0m' from '\\033[1m{row['ba_location']}\\033[0m' \"\n",
    "          f\"has been reviewed by '\\033[1m{row['total_nbr_ratings']}\\033[0m' persons with an average grade of '\\033[1m{row['avg_grade']:.2f}\\033[0m'.\")\n",
    "    i += 1\n",
    "    if i > 5: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          country  num_users  avg_nbr_ratings\n",
      "192     United States, California    14442.0        87.763968\n",
      "225   United States, Pennsylvania    10321.0       109.247726\n",
      "219       United States, New York     8784.0        88.185159\n",
      "200       United States, Illinois     8272.0       106.209645\n",
      "208  United States, Massachusetts     7332.0        71.465746\n",
      "..                            ...        ...              ...\n",
      "184                        Tuvalu        1.0         0.500000\n",
      "183                  Turkmenistan        1.0        34.500000\n",
      "68                      Greenland        1.0       187.000000\n",
      "66                      Gibraltar        1.0         0.500000\n",
      "168                         Sudan        1.0         1.500000\n",
      "\n",
      "[250 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "#3. Now we deep into the identity of the customers, first by analyzing the number of reviewers per country in percentage and then by analyzing their average grade\n",
    "import pandas as pd\n",
    "\n",
    "# Step 1: Count the number of users per country from both ba_users and rb_users\n",
    "users_per_country = ba_users['location'].value_counts().reset_index()\n",
    "users_per_country.columns = ['country', 'num_users_ba']\n",
    "\n",
    "users_per_country2 = rb_users['location'].value_counts().reset_index()\n",
    "users_per_country2.columns = ['country', 'num_users_rb']\n",
    "\n",
    "\n",
    "total_users_per_country = pd.merge(users_per_country, users_per_country2, on='country', how='outer').fillna(0)\n",
    "total_users_per_country['num_users'] = total_users_per_country['num_users_ba'] + total_users_per_country['num_users_rb']\n",
    "\n",
    "\n",
    "avg_ratings_ba = ba_users.groupby('location')['nbr_ratings'].mean().reset_index()\n",
    "avg_ratings_ba.columns = ['country', 'avg_nbr_ratings_ba']\n",
    "\n",
    "avg_ratings_rb = rb_users.groupby('location')['nbr_ratings'].mean().reset_index()\n",
    "avg_ratings_rb.columns = ['country', 'avg_nbr_ratings_rb']\n",
    "\n",
    "# \n",
    "avg_ratings_per_country = pd.merge(avg_ratings_ba, avg_ratings_rb, on='country', how='outer').fillna(0)\n",
    "avg_ratings_per_country['avg_nbr_ratings'] = (avg_ratings_per_country['avg_nbr_ratings_ba'] + avg_ratings_per_country['avg_nbr_ratings_rb']) / 2\n",
    "\n",
    "\n",
    "country_analysis = pd.merge(total_users_per_country[['country', 'num_users']], avg_ratings_per_country[['country', 'avg_nbr_ratings']], on='country', how='left')\n",
    "country_analysis = country_analysis.sort_values(by='num_users', ascending=False)\n",
    "\n",
    "print(country_analysis)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          country  num_users  avg_nbr_ratings\n",
      "0       United States, California      11638        56.556109\n",
      "1     United States, Pennsylvania       8689        75.272413\n",
      "2         United States, New York       7432        66.297094\n",
      "3         United States, Illinois       6866        80.528110\n",
      "4    United States, Massachusetts       6658        62.210424\n",
      "..                            ...        ...              ...\n",
      "189                        Angola          1         6.000000\n",
      "190                    Kazakhstan          1         2.000000\n",
      "191                       Tokelau          1         6.000000\n",
      "192                     Sri Lanka          1         1.000000\n",
      "193                  Sint Maarten          1         1.000000\n",
      "\n",
      "[194 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Assuming your dataset is already loaded into a DataFrame called `data`\n",
    "\n",
    "# Step 1: Count the number of users per country\n",
    "users_per_country = ba_users['location'].value_counts().reset_index()\n",
    "users_per_country.columns = ['country', 'num_users']\n",
    "\n",
    "# Step 2: Calculate the average number of ratings per country\n",
    "# Group by 'location' and calculate the average 'nbr_ratings' per country\n",
    "avg_ratings_per_country = ba_users.groupby('location')['nbr_ratings'].mean().reset_index()\n",
    "avg_ratings_per_country.columns = ['country', 'avg_nbr_ratings']\n",
    "\n",
    "# Step 3: Merge both results to get a combined view\n",
    "country_analysis = pd.merge(users_per_country, avg_ratings_per_country, on='country')\n",
    "\n",
    "# Display the result\n",
    "print(country_analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we will normalise by the countries size to have a better view of the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We can also examine the number of breweries in each country in relation to the number of customers from that country."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Furthermore, as we are a small startup, we would like to know the average number of reviews for each brewery, to understand the competition in the market.\n",
    "#and if it's possible the easily become known in the market."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Then we will try to analyse the time evolution of new breweries.\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "def convert_timestamp_to_date(timestamp):\n",
    "    \"\"\"\n",
    "    Convert a Unix timestamp to a human-readable date format.\n",
    "\n",
    "    Args:\n",
    "        timestamp (int): Unix timestamp.\n",
    "\n",
    "    Returns:\n",
    "        str: Date in 'YYYY-MM-DD HH:MM:SS' format.\n",
    "    \"\"\"\n",
    "    return datetime.fromtimestamp(timestamp).strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "# Example usage\n",
    "example_timestamp = 1322564400\n",
    "print(\"Readable date:\", convert_timestamp_to_date(example_timestamp))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python_env1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
