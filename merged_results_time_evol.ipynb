{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#what information can help us answer the question : parameters : \"Volume_Produced:\" ; \"Total_Sales:\" ; \"Quality_Score:\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Are newcommers welcomed in the beer market?\n",
    "#### What information can help us answer the question : are newcommers welcomed in the beer market?\n",
    "1. The number of breweries that have been established in the last 5 years +list of these breweries\n",
    "2. The number of customer reviews for each of these breweries, which indicates the popularity of the brewery.\n",
    "3. Average rating of the beers from these breweries, which indicates the quality of the beer.\n",
    "4. A graph showing the number of total reviews with time to see if the number of reviews is increasing or decreasing.\n",
    "\n",
    "\n",
    "Additional question : a) does price correlate with quality and rating?\n",
    " \n",
    "\n",
    " Ideas : 1. number of reviews with time\n",
    "            #2. average grade evolution with time \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Info about Datasets\n",
    "\n",
    "### 0.1. beers.csv\n",
    "Contains information about the beers, such as the name, style, and brewery.\n",
    "\n",
    "### 0.2. breweries.csv\n",
    "Contains information about the breweries, such as the name and location.\n",
    "\n",
    "### 0.3. reviews.csv\n",
    "Contains information about the reviews, such as the beer ID, user ID, and rating.\n",
    "\n",
    "### 0.4. ratings.csv\n",
    "Contains information about the ratings, such as the beer ID, user ID, and rating.\n",
    "\n",
    "### 0.5. users.csv\n",
    "Contains information about the users, such as the username and age.\n",
    "\n",
    "---\n",
    "\n",
    "# Summary of Ratings\n",
    "\n",
    "## Dataset: BeerAdvocate\n",
    "\n",
    "- **ba_abv**: 4.8 - Percentage alcohol\n",
    "- **ba_avg**: 3.45 - Average rating (out of 5) of the beer\n",
    "- **ba_avg_computed**: 3.439867 - Computed average rating (out of 5) of the beer\n",
    "- **ba_avg_matched_valid_ratings**: 3.504068\n",
    "- **ba_ba_score**: 80.0 - BA Score is the beer's overall score (out of 100) based on its ranking within its style category, based on a custom Bayesian algorithm\n",
    "- **ba_beer_id**: 19827 - Unique ID for the beer\n",
    "- **ba_beer_name**: Legbiter - Name of the beer\n",
    "- **ba_beer_wout_brewery_name**: Legbiter - Name of the beer without the brewery name\n",
    "- **ba_brewery_id**: 10093 - Unique ID for the brewery\n",
    "- **ba_brewery_name**: Strangford Lough Brewing Company Ltd - Name of the brewery\n",
    "- **ba_bros_score**: 80.0 - The Bros Score is the average score given by the two brothers who founded BeerAdvocate\n",
    "- **ba_nbr_matched_valid_ratings**: 59\n",
    "- **ba_nbr_ratings**: 75 - The number of ratings for the beer\n",
    "- **ba_nbr_reviews**: 59 - The number of reviews for the beer\n",
    "- **ba_style**: English Pale Ale - The style of the beer\n",
    "- **ba_zscore**: -0.649167 - Indicates how many standard deviations a data point is from the mean of the dataset.\n",
    "\n",
    "## Dataset: RateBeer\n",
    "\n",
    "- **rb_abv**: 4.8 - Percentage alcohol\n",
    "- **rb_avg**: 2.79\n",
    "- **rb_avg_computed**: 2.923596\n",
    "- **rb_avg_matched_valid_ratings**: 2.923596\n",
    "- **rb_beer_id**: 37923 - Unique ID for the beer\n",
    "- **rb_beer_name**: Strangford Lough Legbiter - Name of the beer\n",
    "- **rb_beer_wout_brewery_name**: Legbiter - Name of the beer without the brewery name\n",
    "- **rb_brewery_id**: 4959 - Unique ID for the brewery\n",
    "- **rb_brewery_name**: Strangford Lough - Name of the brewery\n",
    "- **rb_nbr_matched_valid_ratings**: 89\n",
    "- **rb_nbr_ratings**: 89 - The number of reviews for the beer\n",
    "- **rb_overall_score**: 23.0 - The overall rating (out of 100)\n",
    "- **rb_style**: Golden Ale/Blond Ale - The style of the beer\n",
    "- **rb_style_score**: 27.0 - The rating in this style category (out of 100)\n",
    "- **rb_zscore**: -0.698304 - Indicates how many standard deviations a data point is from the mean of the dataset.\n",
    "\n",
    "## Dataset: Matched Beer Data\n",
    "\n",
    "- **scores_diff**: 1.0\n",
    "- **scores_sim**: 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part I : Dataset initialization and loading into a pandas DataFrame "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#libraries :\n",
    "import os\n",
    "import tarfile\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import seaborn as sns\n",
    "\n",
    "# Define the list of filenames to be extracted\n",
    "filenames = [\"matched_beer_data.tar.gz\", \"BeerAdvocate.tar.gz\", \"RateBeer.tar.gz\"]\n",
    "base_directory = \"src/data\"\n",
    "\n",
    "# Loop through each filename in the list\n",
    "for fname in filenames:\n",
    "    # Create the extraction folder named data_{base_name}\n",
    "    base_name = os.path.splitext(os.path.splitext(fname)[0])[0]  # Remove both .tar and .gz\n",
    "    extract_folder = os.path.join(base_directory, f\"data_{base_name}\")\n",
    "    \n",
    "    # Create the folder if it does not exist\n",
    "    os.makedirs(extract_folder, exist_ok=True)\n",
    "    \n",
    "    # Check the file extension and open the tar file accordingly\n",
    "    if fname.endswith(\"tar.gz\"):\n",
    "        with tarfile.open(fname, \"r:gz\") as tar:\n",
    "            tar.extractall(path=extract_folder)  \n",
    "            print(f\"Extracted all contents from {fname} to {extract_folder}\")\n",
    "    elif fname.endswith(\"tar\"):\n",
    "        with tarfile.open(fname, \"r:\") as tar:\n",
    "            tar.extractall(path=extract_folder)\n",
    "            print(f\"Extracted all contents from {fname} to {extract_folder}\")\n",
    "    else:\n",
    "        print(f\"The file {fname} is not a recognized .tar.gz or .tar file.\")\n",
    "\n",
    "\n",
    "#3_ open data in pandas dataframe : \n",
    "    #3.1\n",
    "ba_beers = pd.read_csv(\"src/data/data_BeerAdvocate/beers.csv\")\n",
    "ba_breweries = pd.read_csv(\"src/data/data_BeerAdvocate/breweries.csv\")\n",
    "ba_users = pd.read_csv(\"src/data/data_BeerAdvocate/users.csv\")\n",
    "ba_ratings = pd.read_csv(\"src/data/data_BeerAdvocate/ratings.csv\")\n",
    "ba_reviews = pd.read_csv(\"src/data/data_BeerAdvocate/reviews.csv\")\n",
    "\n",
    "    #3.2\n",
    "rb_beers = pd.read_csv(\"src/data/data_RateBeer/beers.csv\")\n",
    "rb_breweries = pd.read_csv(\"src/data/data_RateBeer/breweries.csv\")\n",
    "rb_users = pd.read_csv(\"src/data/data_RateBeer/users.csv\")\n",
    "rb_ratings = pd.read_csv(\"src/data/data_RateBeer/ratings.csv\")\n",
    "rb_reviews = pd.read_csv(\"src/data/data_RateBeer/reviews.csv\")\n",
    "\n",
    "    #3.3 : we will mostly use this files, since they have fusionned the data from the ratebeer and beeradvocate datasets\n",
    "matched_beers = pd.read_csv(\"src/data/data_matched_beer_data/beers.csv\", header=[0, 1])\n",
    "matched_breweries = pd.read_csv(\"src/data/data_matched_beer_data/breweries.csv\", header=[0, 1])\n",
    "matched_ratings = pd.read_csv(\"src/data/data_matched_beer_data/ratings.csv\", header=[0, 1])\n",
    "matched_users_approx = pd.read_csv(\"src/data/data_matched_beer_data/users_approx.csv\", header=[0, 1])\n",
    "matched_users = pd.read_csv(\"src/data/data_matched_beer_data/users.csv\", header=[0, 1])\n",
    "\n",
    "    #3.3.1 : flatten the columns for easier access\n",
    "matched_beers.columns = ['_'.join(col).strip() for col in matched_beers.columns.values]\n",
    "matched_breweries.columns = ['_'.join(col).strip() for col in matched_breweries.columns.values]\n",
    "matched_ratings.columns = ['_'.join(col).strip() for col in matched_ratings.columns.values]\n",
    "matched_users_approx.columns = ['_'.join(map(str, col)).strip() for col in matched_users_approx.columns.values]\n",
    "matched_users.columns = ['_'.join(col).strip() for col in matched_users.columns.values]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Script to transform .txt data into .csv data for ease of use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from src.scripts.load_some_dataset_and_save_it_in_data_directory import extract_full_data as load_txt_data\n",
    "# import re\n",
    "\n",
    "# #convert txt to csv by keeping only the columns we need\n",
    "# # Define file paths and column names\n",
    "# input_file_path = 'src/data/data_BeerAdvocate/ratings.txt'\n",
    "# output_file_path = 'src/data/data_BeerAdvocate/ratings.csv'\n",
    "# columns = [\n",
    "#     'beer_name', 'beer_id', 'brewery_name', 'brewery_id', 'style', 'abv', 'date',\n",
    "#     'user_name', 'user_id', 'appearance', 'aroma', 'palate', 'taste', \n",
    "#     'overall', 'rating'\n",
    "# ]  # we exclude \"text\" and \"review\" \n",
    "\n",
    "# def parse_entry(lines):\n",
    "#     entry = {}\n",
    "#     for line in lines:\n",
    "#         if ': ' in line:\n",
    "#             key, value = line.split(': ', 1)\n",
    "#             if key not in ['text', 'review']: \n",
    "#                 entry[key] = value.strip()\n",
    "#     return entry\n",
    "\n",
    "# data = []\n",
    "# entry_lines = []\n",
    "\n",
    "# with open(input_file_path, 'r', encoding='utf-8') as file:\n",
    "#     for line in file:\n",
    "#         if line.strip():  \n",
    "#             entry_lines.append(line.strip())\n",
    "#         else:\n",
    "#             if entry_lines:  \n",
    "#                 data.append(parse_entry(entry_lines))\n",
    "#                 entry_lines = []\n",
    "\n",
    "#     if entry_lines:\n",
    "#         data.append(parse_entry(entry_lines))\n",
    "\n",
    "\n",
    "# df = pd.DataFrame(data, columns=columns)\n",
    "# df.to_csv(output_file_path, index=False, encoding='utf-8')\n",
    "\n",
    "# print(f\"Data saved to {output_file_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Inspection of the data : Most reviewed beer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. Most reviewed beers and average grade : \n",
    "matched_beers['rb_and_ba_total_nbr_ratings'] = matched_beers['rb_nbr_ratings'] + matched_beers['ba_nbr_ratings']\n",
    "matched_beers['rb_and_ba_total_ratings'] = (matched_beers['rb_avg_computed']*matched_beers['rb_nbr_ratings'] + matched_beers['ba_avg_computed']*matched_beers['ba_nbr_ratings'])/matched_beers['rb_and_ba_total_nbr_ratings']\n",
    "\n",
    "\n",
    "# Merge to add 'country' column to matched_beers\n",
    "matched_beers = pd.merge(\n",
    "    matched_beers,matched_breweries[['rb_id', 'rb_location']],\n",
    "    left_on=['rb_brewery_id'],   # Columns in matched_beers\n",
    "    right_on=['rb_id'],  # Columns in matched_breweries\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "top_beers = matched_beers.sort_values(\n",
    "        by=['rb_and_ba_total_nbr_ratings'],ascending=False\n",
    "    ).head(5)\n",
    "\n",
    "# Print all\n",
    "i = 1\n",
    "for _, row in top_beers[['ba_beer_name', 'ba_brewery_name', 'ba_style', 'rb_and_ba_total_nbr_ratings', 'rb_and_ba_total_ratings', 'rb_location']].iterrows():\n",
    "    print(f\"TOP {i} : The beer '\\033[1m{row['ba_beer_name']}\\033[0m', brewed by '\\033[1m{row['ba_brewery_name']}\\033[0m' from, \\033[1m{row['rb_location']}\\033[0m \"\n",
    "          f\" is of style '\\033[1m{row['ba_style']}\\033[0m' and has been reviewed by '\\033[1m{row['rb_and_ba_total_nbr_ratings']}\\033[0m' persons with an average grade of '\\033[1m{row['rb_and_ba_total_ratings']:.2f}\\033[0m' .\")\n",
    "    i+=1\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3 : Most reviewed brewery."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 2 : Most reviewed breweries and average grade :\n",
    "\n",
    "# Step 1: Calculate the weighted grades for each beer\n",
    "matched_beers['ba_prod_grade_nbr'] = matched_beers['ba_avg_computed'] * matched_beers['ba_nbr_ratings']\n",
    "matched_beers['rb_prod_grade_nbr'] = matched_beers['rb_avg_computed'] * matched_beers['rb_nbr_ratings']\n",
    "\n",
    "# Step 2: Group by brewery to get total weighted grades and ratings counts\n",
    "recap_breweries_info = (\n",
    "    matched_beers\n",
    "    .groupby('ba_brewery_id')[['ba_prod_grade_nbr', 'rb_prod_grade_nbr', 'ba_nbr_ratings', 'rb_nbr_ratings']]\n",
    "    .sum()\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Step 3: Calculate the average grade for each brewery\n",
    "recap_breweries_info['avg_grade'] = (\n",
    "    (recap_breweries_info['ba_prod_grade_nbr'] + recap_breweries_info['rb_prod_grade_nbr']) / \n",
    "    (recap_breweries_info['ba_nbr_ratings'] + recap_breweries_info['rb_nbr_ratings'])\n",
    ")\n",
    "\n",
    "# Step 4: Calculate total ratings count per brewery\n",
    "recap_breweries_info['total_nbr_ratings'] = recap_breweries_info['ba_nbr_ratings'] + recap_breweries_info['rb_nbr_ratings']\n",
    "\n",
    "# Step 5: Select only the final columns and sort by total ratings\n",
    "recap_breweries_info = (\n",
    "    recap_breweries_info[['ba_brewery_id', 'avg_grade', 'total_nbr_ratings']]\n",
    "    .sort_values(by='total_nbr_ratings', ascending=False)\n",
    ")\n",
    "\n",
    "# Step 6: Merge with brewery information to add name and location\n",
    "recap_breweries_info = pd.merge(\n",
    "    recap_breweries_info,\n",
    "    matched_breweries[['ba_id', 'ba_name', 'ba_location']],\n",
    "    left_on='ba_brewery_id',  \n",
    "    right_on='ba_id',           \n",
    "    how=\"left\"\n",
    ").drop(columns=['ba_id'])  # Drop the 'ba_id' column\n",
    "\n",
    "# Print each brewery's information\n",
    "i = 1\n",
    "for _, row in recap_breweries_info[['ba_brewery_id', 'ba_name', 'ba_location', 'total_nbr_ratings', 'avg_grade']].iterrows():\n",
    "    print(f\"TOP {i}: The brewery '\\033[1m{row['ba_name']}\\033[0m' from '\\033[1m{row['ba_location']}\\033[0m' \"\n",
    "          f\"has been reviewed by '\\033[1m{row['total_nbr_ratings']}\\033[0m' persons with an average grade of '\\033[1m{row['avg_grade']:.2f}\\033[0m'.\")\n",
    "    i += 1\n",
    "    if i > 5: break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Analysis of Customer Identity and origin\n",
    "\n",
    "In this section, we will analyze the identity of the customers by examining the number of reviewers per country in percentage and their average grade. This will help us understand the distribution and behavior of beer reviewers across different regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. Now we deep into the identity of the customers, first by analyzing the number of reviewers per country in percentage and then by analyzing their average grade\n",
    "# Step 1: Count the number of users per country from both ba_users and rb_users\n",
    "users_per_country = ba_users['location'].value_counts().reset_index()\n",
    "users_per_country.columns = ['country', 'num_users_ba']\n",
    "\n",
    "users_per_country2 = rb_users['location'].value_counts().reset_index()\n",
    "users_per_country2.columns = ['country', 'num_users_rb']\n",
    "\n",
    "# Combine the user counts from both datasets\n",
    "total_users_per_country = pd.merge(users_per_country, users_per_country2, on='country', how='outer').fillna(0)\n",
    "total_users_per_country['num_users'] = total_users_per_country['num_users_ba'] + total_users_per_country['num_users_rb']\n",
    "\n",
    "# Step 2: Calculate the average number of ratings per country from both ba_users and rb_users\n",
    "avg_ratings_ba = ba_users.groupby('location')['nbr_ratings'].mean().reset_index()\n",
    "avg_ratings_ba.columns = ['country', 'avg_nbr_ratings_ba']\n",
    "\n",
    "avg_ratings_rb = rb_users.groupby('location')['nbr_ratings'].mean().reset_index()\n",
    "avg_ratings_rb.columns = ['country', 'avg_nbr_ratings_rb']\n",
    "\n",
    "# Step 3: Merge the average ratings from both datasets and calculate the combined average\n",
    "avg_ratings_per_country = pd.merge(avg_ratings_ba, avg_ratings_rb, on='country', how='outer').fillna(0)\n",
    "\n",
    "# Calculate the weighted average number of ratings\n",
    "avg_ratings_per_country = pd.merge(avg_ratings_per_country, total_users_per_country[['country', 'num_users_ba', 'num_users_rb']], on='country', how='left')\n",
    "avg_ratings_per_country['avg_nbr_ratings'] = (\n",
    "    (avg_ratings_per_country['avg_nbr_ratings_ba'] * avg_ratings_per_country['num_users_ba']) + \n",
    "    (avg_ratings_per_country['avg_nbr_ratings_rb'] * avg_ratings_per_country['num_users_rb'])\n",
    ") / (avg_ratings_per_country['num_users_ba'] + avg_ratings_per_country['num_users_rb'])\n",
    "\n",
    "# Step 4: Create the final country analysis table\n",
    "country_analysis = pd.merge(\n",
    "    total_users_per_country[['country', 'num_users']],\n",
    "    avg_ratings_per_country[['country', 'avg_nbr_ratings']],\n",
    "    on='country', \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Sort the results by the total number of users\n",
    "country_analysis = country_analysis.sort_values(by='num_users', ascending=False)\n",
    "\n",
    "# Display the result\n",
    "print(country_analysis)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to remove all entrie containing \"United States\" in the 'country' column and replace them with a single entry\n",
    "\n",
    "# This pattern captures any entry that starts with \"United States\" as a whole word\n",
    "us_rows = country_analysis[country_analysis['country'].str.contains(r\"\\bUnited States\\b\", case=False, na=False)]\n",
    "\n",
    "#Calculate product of num_users and avg_nbr_ratings for all \"United States\" entries\n",
    "total_product_ratings_time_population = (us_rows['num_users'] * us_rows['avg_nbr_ratings']).sum()\n",
    "\n",
    "#Sum the total nbr of users (reviews) for all \"United States\" entries\n",
    "total_nbr_users = us_rows['num_users'].sum()\n",
    "\n",
    "# Remove the rows containing \"United States\"\n",
    "country_info = country_analysis[~country_analysis['country'].str.contains(r\"\\bUnited States\\b\", case=False, na=False)]\n",
    "\n",
    "# Creates a new single row for the USA entry\n",
    "new_row = pd.DataFrame({\n",
    "    'country': ['United States'],\n",
    "    'num_users': [total_nbr_users],\n",
    "    'avg_nbr_ratings': [total_product_ratings_time_population / total_nbr_users]  # Calculates average ratings\n",
    "})\n",
    "\n",
    "#summaries all the infos in the country_info dataframe\n",
    "country_info = pd.concat([country_info, new_row], ignore_index=True) \n",
    "country_info = country_info.sort_values(by='num_users', ascending=False)\n",
    "\n",
    "# Display the modified DataFrame\n",
    "print(country_info)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we will add the information about the population to the country_info dataframe \n",
    "countries_population = pd.read_csv(\"src/data/Data_Countries_population/countries_population.csv\") #taken from world bank group\n",
    "countries_population2010 = countries_population[['Country Name', '2010']] #since the data represents the ratings from 2001 to 2017, we will use the 2010 year as a reference.\n",
    "\n",
    "country_analysis2 = pd.merge(country_info, countries_population2010[['Country Name', '2010']], left_on='country', right_on='Country Name', how='left')\n",
    "\n",
    "country_analysis2 = country_analysis2.drop(columns=['Country Name'])\n",
    "#Now we will will count the number of Nan in the 2010 column, which represents the countries that have a slightly different name in the world bank group dataset\n",
    "#we will rename them by hand in the world bank group dataset.\n",
    "\n",
    "# Count the number of NaN values in the '2010' column\n",
    "num_nan_2010 = country_analysis2['2010'].isnull().sum()\n",
    "print (num_nan_2010)\n",
    "# Note: We reduced the NaN values to 48. The remaining \"countries\" were left because most of them are small regions that had to be attached to bigger ones because of \n",
    "# geopolitical reasons and others were small countries/islands with a low user counts (max 10), \n",
    "# making their impact on the analysis negligible.\n",
    "country_analysis2 = country_analysis2.dropna()\n",
    "\n",
    "#rename the 2010 column to 'population_in_2010'\n",
    "country_analysis2 = country_analysis2.rename(columns={'2010': 'population_in_2010'})\n",
    "country_analysis2['percentage_reviewers_per_country'] = (country_analysis2['num_users'] / country_analysis2['population_in_2010']) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# add brewery info to \"country_analysis2\" dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3.2 : add infos about the breweries to \"country_analysis2\", with the same method as to add the infos about the users\n",
    "# Step 1: Count the number of breweries per country from both ba and rb datasets\n",
    "breweries_per_country = ba_breweries['location'].value_counts().reset_index()\n",
    "breweries_per_country.columns = ['country', 'nbr_breweries_ba']\n",
    "breweries_per_country2 = rb_users['location'].value_counts().reset_index()\n",
    "breweries_per_country2.columns = ['country', 'nbr_breweries_rb']\n",
    "\n",
    "# Combine the breweries counts from both datasets\n",
    "total_breweries_per_country = pd.merge(breweries_per_country, breweries_per_country2, on='country', how='outer').fillna(0)\n",
    "total_breweries_per_country['nbr_breweries'] = total_breweries_per_country['nbr_breweries_ba'] + total_breweries_per_country['nbr_breweries_rb']\n",
    "\n",
    "# Step 2: remove the entries containing \"United States\" and replace them with a single entry\n",
    "# Identify all entries that start with \"United States\" as a whole word\n",
    "us_rows = total_breweries_per_country[total_breweries_per_country['country'].str.contains(r\"\\bUnited States\\b\", case=False, na=False)]\n",
    "\n",
    "# Calculate the total number of breweries for all \"United States\" entries\n",
    "total_nbr_breweries = us_rows['nbr_breweries'].sum()\n",
    "\n",
    "# Remove the original rows with \"United States\" states\n",
    "total_breweries_with_single_usa = total_breweries_per_country[~total_breweries_per_country['country'].str.contains(r\"\\bUnited States\\b\", case=False, na=False)]\n",
    "\n",
    "# Create a new single row for the combined \"United States\" entry\n",
    "new_row = pd.DataFrame({\n",
    "    'country': ['United States'],\n",
    "    'nbr_breweries': [total_nbr_breweries],\n",
    "    \n",
    "})\n",
    "\n",
    "# Concatenate the new row with the modified DataFrame\n",
    "total_breweries_with_single_usa = pd.concat([total_breweries_with_single_usa, new_row], ignore_index=True)\n",
    "total_breweries_with_single_usa = total_breweries_with_single_usa.sort_values(by='nbr_breweries', ascending=False)\n",
    "\n",
    "# step 3 : merge with country analysis2 : \n",
    "total_breweries_with_single_usa=total_breweries_with_single_usa.drop(columns=['nbr_breweries_ba', 'nbr_breweries_rb'])\n",
    "country_analysis2 = pd.merge(country_analysis2, total_breweries_with_single_usa, on='country', how='left')\n",
    "print(country_analysis2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# discard countries with less than 50 users\n",
    "filtered_data = country_analysis2[country_analysis2['num_users'] >= 50]\n",
    "\n",
    "# Plot 1: Nbr of Users and population per Country (Log Scale)\n",
    "fig, ax1 = plt.subplots(figsize=(12, 6))\n",
    "# Plot Number of Users\n",
    "ax1.bar(filtered_data['country'], filtered_data['num_users'], color='skyblue', label='Number of Users')\n",
    "ax1.set_xlabel('Country')\n",
    "ax1.set_ylabel('Number of Users')\n",
    "ax1.set_yscale('log')  \n",
    "ax1.set_title('Number of Users and Population per Country (Log Scale)')\n",
    "ax1.tick_params(axis='x', rotation=90)\n",
    "# Plot also the total Population of the country\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(filtered_data['country'], filtered_data['population_in_2010'], color='green', marker='o', linestyle='-', label='Population (2010)')\n",
    "ax2.set_ylabel('Population in 2010')\n",
    "ax2.set_yscale('log') \n",
    "ax1.legend(loc='upper left')\n",
    "ax2.legend(loc='upper right')\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#Plot 2: Percentage of Reviewers per Country (Log Scale)\n",
    "ig, ax1 = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "ax1.bar(filtered_data['country'], filtered_data['num_users'], color='skyblue', label='Number of Users')\n",
    "ax1.set_xlabel('Country')\n",
    "ax1.set_ylabel('Number of Users')\n",
    "ax1.set_yscale('log')  \n",
    "ax1.set_title('Number of Users and Percentage of Users per Country (Log Scale)')\n",
    "ax1.tick_params(axis='x', rotation=90)\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(filtered_data['country'], filtered_data['percentage_reviewers_per_country'], color='green', marker='o', linestyle='-', label='Percentage of Reviewers')\n",
    "ax2.set_ylabel('Percentage of Reviewers')\n",
    "ax2.set_yscale('log') \n",
    "ax1.legend(loc='upper left')\n",
    "ax2.legend(loc='upper right')\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot 3: Average Number of Ratings per Country (Log Scale)\n",
    "filtered_data2 = filtered_data.sort_values(by='avg_nbr_ratings', ascending=False)\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(filtered_data2['country'], filtered_data2['avg_nbr_ratings'], color='salmon')\n",
    "plt.xlabel('Country')\n",
    "plt.ylabel('Average Number of Ratings')\n",
    "plt.title('Average Number of Ratings per Country (Log Scale)')\n",
    "plt.yscale('log')  # Set y-axis to log scale\n",
    "plt.xticks(rotation=90)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3.1 : We can also examine the number of breweries in each country in relation to the number of customers from that country."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(country_analysis2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Furthermore, as we are a small startup, we would like to know the average number of reviews that breweries from a country can get, to understand the competition \n",
    "# in the market and if it's possible the easily become known in the market.\n",
    "\n",
    "# discard countries with less than 50 users\n",
    "filtered_data = country_analysis2[country_analysis2['num_users'] >= 50]\n",
    "# Scatter plot of nbr breweries vs. nbr of usersfor each country\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(filtered_data['num_users'], filtered_data['nbr_breweries'])\n",
    "\n",
    "# Add labels for each country \n",
    "for i, row in filtered_data.iterrows():\n",
    "    plt.text(row['num_users'], row['nbr_breweries'], row['country'])\n",
    "\n",
    "# log scale to handle wide ranges (mostly for the usa)\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "\n",
    "# Labels and title\n",
    "plt.xlabel('Number of Users (log scale)')\n",
    "plt.ylabel('Number of Breweries (log scale)')\n",
    "plt.title('Number of Breweries vs. Number of Users per Country')\n",
    "\n",
    "# Show plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume 'population_in_2010' column exists in your 'country_analysis2' DataFrame for each country\n",
    "# Filter countries with at least 50 users\n",
    "filtered_data = country_analysis2[country_analysis2['num_users'] >= 5]\n",
    "\n",
    "# Calculate users and breweries per million people to normalize by population\n",
    "filtered_data['users_per_million'] = (filtered_data['num_users'] / filtered_data['population_in_2010']) * 1e6\n",
    "filtered_data['breweries_per_million'] = (filtered_data['nbr_breweries'] / filtered_data['population_in_2010']) * 1e6\n",
    "\n",
    "# Scatter plot of breweries per million vs. users per million for each country\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(filtered_data['users_per_million'], filtered_data['breweries_per_million'], color='green')\n",
    "\n",
    "# Add labels for each country\n",
    "for i, row in filtered_data.iterrows():\n",
    "    plt.text(row['users_per_million'], row['breweries_per_million'], row['country'], fontsize=8)\n",
    "\n",
    "# Use log scale to handle wide ranges\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "\n",
    "# Labels and title\n",
    "plt.xlabel('nbr of users normalised by nbr of inhabitants per country (log scale)')\n",
    "plt.ylabel('nbr of Breweries normalised by nbr of inhabitants per country (log scale)')\n",
    "plt.title('normalised number of Breweries vs. normalised number of Users per Country')\n",
    "\n",
    "# Show plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_data = country_analysis2[country_analysis2['num_users'] >= 5]\n",
    "\n",
    "# Calculate users per million people to normalize by population\n",
    "filtered_data['norm_num_users'] = (filtered_data['num_users'] / filtered_data['population_in_2010']) \n",
    "\n",
    "# Sort values by users per million for better visualization and select the top 15 countries\n",
    "filtered_data = filtered_data.sort_values(by='norm_num_users', ascending=False).head(15)\n",
    "\n",
    "# Plot the pie chart of users per million\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.pie(\n",
    "    filtered_data['norm_num_users'], \n",
    "    labels=filtered_data['country'], \n",
    "    autopct='%1.1f%%',  #to have the percentages on the pie chart\n",
    "    startangle=140,\n",
    "    wedgeprops=dict(edgecolor='black')\n",
    ")\n",
    "\n",
    "# Title\n",
    "plt.title('Percentage of Users per Country Normalised by Population (Top 15)')\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter countries with at least 5 users\n",
    "filtered_data = country_analysis2[country_analysis2['num_users'] >= 5]\n",
    "\n",
    "# Calculate users per million people per brewery to normalize by population and breweries\n",
    "filtered_data['norm_num_users'] = (filtered_data['num_users'] / (np.log1p(filtered_data['population_in_2010']) * filtered_data['nbr_breweries']))\n",
    "\n",
    "# Sort values by normalized nbr of users for better visualization and select the top 15 countries\n",
    "filtered_data = filtered_data.sort_values(by='norm_num_users', ascending=False).head(15)\n",
    "\n",
    "# Plot the pie chart of users per million per brewery\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.pie(\n",
    "    filtered_data['norm_num_users'], \n",
    "    labels=filtered_data['country'], \n",
    "    autopct='%1.1f%%',  # Display percentages on the pie chart\n",
    "    startangle=140,\n",
    "    wedgeprops=dict(edgecolor='black')\n",
    ")\n",
    "\n",
    "# Title\n",
    "plt.title('Percentage of Users per Country Normalised by Population and nbr of Breweries (Top 15)')\n",
    "\n",
    "# Show plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Then we will try to analyse the time evolution of new breweries.\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "def convert_timestamp_to_date(timestamp):\n",
    "    \"\"\"\n",
    "    Convert a Unix timestamp to a human-readable date format.\n",
    "\n",
    "    Args:\n",
    "        timestamp (int): Unix timestamp.\n",
    "\n",
    "    Returns:\n",
    "        str: Date in 'YYYY-MM-DD HH:MM:SS' format.\n",
    "    \"\"\"\n",
    "    return datetime.fromtimestamp(timestamp).strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "# Example usage\n",
    "example_timestamp = 1322564400\n",
    "print(\"Readable date:\", convert_timestamp_to_date(example_timestamp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_time = 1438423200\n",
    "\n",
    "def convert_unix_to_datetime(unix_time):\n",
    "    return pd.to_datetime(unix_time, unit='s')\n",
    " \n",
    "print(convert_unix_to_datetime(example_time))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert date to datetime, keep only days\n",
    "ba_ratings['date'] = pd.to_datetime(ba_ratings['date'], origin='unix', unit='s').dt.date\n",
    "print(ba_ratings.head())\n",
    "rb_ratings['date'] = pd.to_datetime(rb_ratings['date'], origin='unix', unit='s').dt.date\n",
    "print(rb_ratings.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#plot number of reviews per day\n",
    "rb_ratings['date'].value_counts().sort_index().plot()\n",
    "\n",
    "#add 5 days moving average\n",
    "ba_ratings['date'].value_counts().sort_index().rolling(window=30).mean().plot()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot number of reviews per day\n",
    "rb_ratings['date'].value_counts().sort_index().plot()\n",
    "\n",
    "#add 5 days moving average\n",
    "rb_ratings['date'].value_counts().sort_index().rolling(window=30).mean().plot()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#look at the evolution of the average grade over time\n",
    "ba_ratings.groupby('date')['rating'].mean().plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rb_ratings.groupby('date')['rating'].mean().plot()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#average grade per type of beer\n",
    "# Plot only the top 20 beer styles by average rating\n",
    "top_styles = ba_ratings.groupby('style')['rating'].mean().sort_values().tail(50)\n",
    "top_styles.plot(kind='barh', figsize=(10, 8), fontsize=8)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_styles = rb_ratings.groupby('style')['rating'].mean().sort_values().tail(50)\n",
    "top_styles.plot(kind='barh', figsize=(10, 8), fontsize=8)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the number of reviews per style\n",
    "number_of_reviews_per_style = ba_ratings['style'].value_counts().head(50)\n",
    "number_of_reviews_per_style.plot(kind='barh', figsize=(10, 8), fontsize=8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a seasonal dataframe by keeping only the month and day\n",
    "ba_ratings['date'] = pd.to_datetime(ba_ratings['date'])\n",
    "ba_ratings['month_day'] = ba_ratings['date'].dt.strftime('%m-%d')\n",
    "print(ba_ratings.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rb_ratings['date'] = pd.to_datetime(rb_ratings['date'])\n",
    "rb_ratings['month_day'] = rb_ratings['date'].dt.strftime('%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the number of reviews per day of the year\n",
    "\n",
    "#Not perfect as should be normalized for each year\n",
    "\n",
    "number_of_reviews_per_day_BA = ba_ratings['month_day'].value_counts().sort_index().rolling(window=7).mean() \n",
    "number_of_reviews_per_day_BA.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_reviews_per_day_RB = rb_ratings['month_day'].value_counts().sort_index().rolling(window=7).mean() \n",
    "number_of_reviews_per_day_RB.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_styles_BA = ba_ratings.groupby('style')['rating'].mean().sort_values().tail(5)\n",
    "print(top_styles_BA)\n",
    "top_styles_RB = rb_ratings.groupby('style')['rating'].mean().sort_values().tail(5)\n",
    "print(top_styles_RB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#average grade (rolling average) per type of beer for top_styles on seasonal data\n",
    "ba_ratings_top = ba_ratings[ba_ratings['style'].isin(top_styles_BA.index)]\n",
    "ba_ratings_top.groupby(['style', 'month_day'])['rating'].mean().unstack('style').rolling(window=7).mean().plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rb_ratings_top = rb_ratings[rb_ratings['style'].isin(top_styles_RB.index)]\n",
    "rb_ratings_top.groupby(['style', 'month_day'])['rating'].mean().unstack('style').rolling(window=7).mean().plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python_env1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
